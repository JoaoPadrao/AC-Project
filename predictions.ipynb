{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.read_csv('data/clean/cleaned_teams.csv')\n",
    "players = pd.read_csv('data/clean/cleaned_players.csv')\n",
    "players_teams = pd.read_csv('data/clean/cleaned_players_teams.csv')\n",
    "coaches = pd.read_csv('data/clean/cleaned_coaches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coach_experience_for_team(coaches, team_id, year):\n",
    "    team_coaches = coaches[(coaches['tmID'] == team_id) & (coaches['year'] == year)]\n",
    "    total_games = team_coaches['won'].sum() + team_coaches['lost'].sum()\n",
    "    \n",
    "    total_coach_experience = 0\n",
    "    \n",
    "    for _, coach in team_coaches.iterrows():\n",
    "        coach_history = coaches[(coaches['coachID'] == coach['coachID']) & (coaches['year'] < year)]\n",
    "        coach_history = coach_history.sort_values(by='year', ascending=False).head(year)\n",
    "\n",
    "        weights = list(range(year, 0, -1)) \n",
    "        weighted_winrate = sum(coach_history['winrate'] * weights[:len(coach_history)])\n",
    "        total_awards = coach_history['TotalAwards'].sum()\n",
    "        coach_experience = weighted_winrate + total_awards\n",
    "        \n",
    "        coach_games = coach['won'] + coach['lost']\n",
    "        coach_weight = coach_games / total_games if total_games > 0 else 0\n",
    "        total_coach_experience += coach_experience * coach_weight\n",
    "    \n",
    "    return total_coach_experience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year tmID franchID confID  rank playoff firstRound semis finals  o_fgm  \\\n",
      "4     3  CHA      CHA     EA     2       Y          L   NaN    NaN    770   \n",
      "\n",
      "   ...  player_total_PostTurnovers  player_total_PostPF  \\\n",
      "4  ...                        23.0                 28.0   \n",
      "\n",
      "   player_total_PostfgAttempted  player_total_PostfgMade  \\\n",
      "4                         114.0                     42.0   \n",
      "\n",
      "   player_total_PostftAttempted  player_total_PostftMade  \\\n",
      "4                          19.0                      9.0   \n",
      "\n",
      "   player_total_PostthreeAttempted  player_total_PostthreeMade  \\\n",
      "4                             42.0                        11.0   \n",
      "\n",
      "   player_total_PostDQ  player_total_awards  \n",
      "4                  0.0                  0.0  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "    year tmID franchID confID  rank playoff firstRound semis finals  o_fgm  \\\n",
      "15     3  CLE      CLE     EA     7       N        NaN   NaN    NaN    760   \n",
      "\n",
      "    ...  player_total_PostTurnovers  player_total_PostPF  \\\n",
      "15  ...                         0.0                  0.0   \n",
      "\n",
      "    player_total_PostfgAttempted  player_total_PostfgMade  \\\n",
      "15                           0.0                      0.0   \n",
      "\n",
      "    player_total_PostftAttempted  player_total_PostftMade  \\\n",
      "15                           0.0                      0.0   \n",
      "\n",
      "    player_total_PostthreeAttempted  player_total_PostthreeMade  \\\n",
      "15                              0.0                         0.0   \n",
      "\n",
      "    player_total_PostDQ  player_total_awards  \n",
      "15                  0.0                  0.0  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "    year tmID franchID confID  rank playoff firstRound semis finals  o_fgm  \\\n",
      "26     3  DET      DET     EA     8       N        NaN   NaN    NaN    766   \n",
      "\n",
      "    ...  player_total_PostTurnovers  player_total_PostPF  \\\n",
      "26  ...                         0.0                  0.0   \n",
      "\n",
      "    player_total_PostfgAttempted  player_total_PostfgMade  \\\n",
      "26                           0.0                      0.0   \n",
      "\n",
      "    player_total_PostftAttempted  player_total_PostftMade  \\\n",
      "26                           0.0                      0.0   \n",
      "\n",
      "    player_total_PostthreeAttempted  player_total_PostthreeMade  \\\n",
      "26                              0.0                         0.0   \n",
      "\n",
      "    player_total_PostDQ  player_total_awards  \n",
      "26                  0.0                  0.0  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "    year tmID franchID confID  rank playoff firstRound semis finals  o_fgm  \\\n",
      "36     3  HOU      HOU     WE     2       Y          L   NaN    NaN    755   \n",
      "\n",
      "    ...  player_total_PostTurnovers  player_total_PostPF  \\\n",
      "36  ...                        29.0                 57.0   \n",
      "\n",
      "    player_total_PostfgAttempted  player_total_PostfgMade  \\\n",
      "36                         213.0                     78.0   \n",
      "\n",
      "    player_total_PostftAttempted  player_total_PostftMade  \\\n",
      "36                          53.0                     43.0   \n",
      "\n",
      "    player_total_PostthreeAttempted  player_total_PostthreeMade  \\\n",
      "36                             48.0                        15.0   \n",
      "\n",
      "    player_total_PostDQ  player_total_awards  \n",
      "36                  0.0                  2.0  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "    year tmID franchID confID  rank playoff firstRound semis finals  o_fgm  \\\n",
      "45     3  IND      IND     EA     4       Y          L   NaN    NaN    731   \n",
      "\n",
      "    ...  player_total_PostTurnovers  player_total_PostPF  \\\n",
      "45  ...                        44.0                 52.0   \n",
      "\n",
      "    player_total_PostfgAttempted  player_total_PostfgMade  \\\n",
      "45                         170.0                     75.0   \n",
      "\n",
      "    player_total_PostftAttempted  player_total_PostftMade  \\\n",
      "45                          40.0                     29.0   \n",
      "\n",
      "    player_total_PostthreeAttempted  player_total_PostthreeMade  \\\n",
      "45                             54.0                        19.0   \n",
      "\n",
      "    player_total_PostDQ  player_total_awards  \n",
      "45                  1.0                  1.0  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "    year tmID franchID confID  rank playoff firstRound semis finals  o_fgm  \\\n",
      "55     3  LAS      LAS     WE     1       Y          W     W      W    891   \n",
      "\n",
      "    ...  player_total_PostTurnovers  player_total_PostPF  \\\n",
      "55  ...                        76.0                128.0   \n",
      "\n",
      "    player_total_PostfgAttempted  player_total_PostfgMade  \\\n",
      "55                         372.0                    170.0   \n",
      "\n",
      "    player_total_PostftAttempted  player_total_PostftMade  \\\n",
      "55                         119.0                     91.0   \n",
      "\n",
      "    player_total_PostthreeAttempted  player_total_PostthreeMade  \\\n",
      "55                             88.0                        34.0   \n",
      "\n",
      "    player_total_PostDQ  player_total_awards  \n",
      "55                  2.0                  2.0  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "    year tmID franchID confID  rank playoff firstRound semis finals  o_fgm  \\\n",
      "65     3  MIA      MIA     EA     6       N        NaN   NaN    NaN    774   \n",
      "\n",
      "    ...  player_total_PostTurnovers  player_total_PostPF  \\\n",
      "65  ...                         0.0                  0.0   \n",
      "\n",
      "    player_total_PostfgAttempted  player_total_PostfgMade  \\\n",
      "65                           0.0                      0.0   \n",
      "\n",
      "    player_total_PostftAttempted  player_total_PostftMade  \\\n",
      "65                           0.0                      0.0   \n",
      "\n",
      "    player_total_PostthreeAttempted  player_total_PostthreeMade  \\\n",
      "65                              0.0                         0.0   \n",
      "\n",
      "    player_total_PostDQ  player_total_awards  \n",
      "65                  0.0                  0.0  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "    year tmID franchID confID  rank playoff firstRound semis finals  o_fgm  \\\n",
      "68     3  MIN      MIN     WE     8       N        NaN   NaN    NaN    727   \n",
      "\n",
      "    ...  player_total_PostTurnovers  player_total_PostPF  \\\n",
      "68  ...                         0.0                  0.0   \n",
      "\n",
      "    player_total_PostfgAttempted  player_total_PostfgMade  \\\n",
      "68                           0.0                      0.0   \n",
      "\n",
      "    player_total_PostftAttempted  player_total_PostftMade  \\\n",
      "68                           0.0                      0.0   \n",
      "\n",
      "    player_total_PostthreeAttempted  player_total_PostthreeMade  \\\n",
      "68                              0.0                         0.0   \n",
      "\n",
      "    player_total_PostDQ  player_total_awards  \n",
      "68                  0.0                  0.0  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "    year tmID franchID confID  rank playoff firstRound semis finals  o_fgm  \\\n",
      "78     3  NYL      NYL     EA     1       Y          W     W      L    772   \n",
      "\n",
      "    ...  player_total_PostTurnovers  player_total_PostPF  \\\n",
      "78  ...                        83.0                130.0   \n",
      "\n",
      "    player_total_PostfgAttempted  player_total_PostfgMade  \\\n",
      "78                         443.0                    214.0   \n",
      "\n",
      "    player_total_PostftAttempted  player_total_PostftMade  \\\n",
      "78                         143.0                    107.0   \n",
      "\n",
      "    player_total_PostthreeAttempted  player_total_PostthreeMade  \\\n",
      "78                            108.0                        42.0   \n",
      "\n",
      "    player_total_PostDQ  player_total_awards  \n",
      "78                  0.0                  0.0  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "    year tmID franchID confID  rank playoff firstRound semis finals  o_fgm  \\\n",
      "88     3  ORL      CON     EA     5       N        NaN   NaN    NaN    808   \n",
      "\n",
      "    ...  player_total_PostTurnovers  player_total_PostPF  \\\n",
      "88  ...                         0.0                  0.0   \n",
      "\n",
      "    player_total_PostfgAttempted  player_total_PostfgMade  \\\n",
      "88                           0.0                      0.0   \n",
      "\n",
      "    player_total_PostftAttempted  player_total_PostftMade  \\\n",
      "88                           0.0                      0.0   \n",
      "\n",
      "    player_total_PostthreeAttempted  player_total_PostthreeMade  \\\n",
      "88                              0.0                         0.0   \n",
      "\n",
      "    player_total_PostDQ  player_total_awards  \n",
      "88                  0.0                  0.0  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "    year tmID franchID confID  rank playoff firstRound semis finals  o_fgm  \\\n",
      "91     3  PHO      PHO     WE     7       N        NaN   NaN    NaN    793   \n",
      "\n",
      "    ...  player_total_PostTurnovers  player_total_PostPF  \\\n",
      "91  ...                         0.0                  0.0   \n",
      "\n",
      "    player_total_PostfgAttempted  player_total_PostfgMade  \\\n",
      "91                           0.0                      0.0   \n",
      "\n",
      "    player_total_PostftAttempted  player_total_PostftMade  \\\n",
      "91                           0.0                      0.0   \n",
      "\n",
      "    player_total_PostthreeAttempted  player_total_PostthreeMade  \\\n",
      "91                              0.0                         0.0   \n",
      "\n",
      "    player_total_PostDQ  player_total_awards  \n",
      "91                  0.0                  0.0  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "     year tmID franchID confID  rank playoff firstRound semis finals  o_fgm  \\\n",
      "101     3  POR      POR     WE     5       N        NaN   NaN    NaN    829   \n",
      "\n",
      "     ...  player_total_PostTurnovers  player_total_PostPF  \\\n",
      "101  ...                         0.0                  0.0   \n",
      "\n",
      "     player_total_PostfgAttempted  player_total_PostfgMade  \\\n",
      "101                           0.0                      0.0   \n",
      "\n",
      "     player_total_PostftAttempted  player_total_PostftMade  \\\n",
      "101                           0.0                      0.0   \n",
      "\n",
      "     player_total_PostthreeAttempted  player_total_PostthreeMade  \\\n",
      "101                              0.0                         0.0   \n",
      "\n",
      "     player_total_PostDQ  player_total_awards  \n",
      "101                  0.0                  0.0  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "     year tmID franchID confID  rank playoff firstRound semis finals  o_fgm  \\\n",
      "104     3  SAC      SAC     WE     6       N        NaN   NaN    NaN    780   \n",
      "\n",
      "     ...  player_total_PostTurnovers  player_total_PostPF  \\\n",
      "104  ...                         0.0                  0.0   \n",
      "\n",
      "     player_total_PostfgAttempted  player_total_PostfgMade  \\\n",
      "104                           0.0                      0.0   \n",
      "\n",
      "     player_total_PostftAttempted  player_total_PostftMade  \\\n",
      "104                           0.0                      0.0   \n",
      "\n",
      "     player_total_PostthreeAttempted  player_total_PostthreeMade  \\\n",
      "104                              0.0                         0.0   \n",
      "\n",
      "     player_total_PostDQ  player_total_awards  \n",
      "104                  0.0                  0.0  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "     year tmID franchID confID  rank playoff firstRound semis finals  o_fgm  \\\n",
      "121     3  SEA      SEA     WE     4       Y          L   NaN    NaN    794   \n",
      "\n",
      "     ...  player_total_PostTurnovers  player_total_PostPF  \\\n",
      "121  ...                        35.0                 35.0   \n",
      "\n",
      "     player_total_PostfgAttempted  player_total_PostfgMade  \\\n",
      "121                         112.0                     39.0   \n",
      "\n",
      "     player_total_PostftAttempted  player_total_PostftMade  \\\n",
      "121                          37.0                     32.0   \n",
      "\n",
      "     player_total_PostthreeAttempted  player_total_PostthreeMade  \\\n",
      "121                             37.0                        10.0   \n",
      "\n",
      "     player_total_PostDQ  player_total_awards  \n",
      "121                  0.0                  0.0  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "     year tmID franchID confID  rank playoff firstRound semis finals  o_fgm  \\\n",
      "131     3  UTA      SAS     WE     3       Y          W   NaN    NaN    843   \n",
      "\n",
      "     ...  player_total_PostTurnovers  player_total_PostPF  \\\n",
      "131  ...                        79.0                 98.0   \n",
      "\n",
      "     player_total_PostfgAttempted  player_total_PostfgMade  \\\n",
      "131                         307.0                    133.0   \n",
      "\n",
      "     player_total_PostftAttempted  player_total_PostftMade  \\\n",
      "131                         111.0                     80.0   \n",
      "\n",
      "     player_total_PostthreeAttempted  player_total_PostthreeMade  \\\n",
      "131                             49.0                        16.0   \n",
      "\n",
      "     player_total_PostDQ  player_total_awards  \n",
      "131                  1.0                  0.0  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "     year tmID franchID confID  rank playoff firstRound semis finals  o_fgm  \\\n",
      "134     3  WAS      WAS     EA     3       Y          W   NaN    NaN    806   \n",
      "\n",
      "     ...  player_total_PostTurnovers  player_total_PostPF  \\\n",
      "134  ...                        47.0                 85.0   \n",
      "\n",
      "     player_total_PostfgAttempted  player_total_PostfgMade  \\\n",
      "134                         294.0                    133.0   \n",
      "\n",
      "     player_total_PostftAttempted  player_total_PostftMade  \\\n",
      "134                          77.0                     59.0   \n",
      "\n",
      "     player_total_PostthreeAttempted  player_total_PostthreeMade  \\\n",
      "134                             72.0                        26.0   \n",
      "\n",
      "     player_total_PostDQ  player_total_awards  \n",
      "134                  0.0                  1.0  \n",
      "\n",
      "[1 rows x 105 columns]\n"
     ]
    }
   ],
   "source": [
    "def predict_team_year_stats(team_id, year): \n",
    "    # Select player ids for the team for that year\n",
    "    players_ids = players_teams[(players_teams['tmID'] == team_id) & (players_teams['year'] == year)]['playerID']\n",
    "    \n",
    "    # Select player stats for last year\n",
    "    team_players = players_teams[(players_teams['playerID'].isin(players_ids)) & (players_teams['year'] == year - 1)]\n",
    "    team_players_bio = players[(players['bioID'].isin(players_ids))]\n",
    "\n",
    "    print(teams.loc[(teams['tmID'] == team_id) & (teams['year'] == year)])\n",
    "    \n",
    "    # Copy the stats from the previous year into the new year    \n",
    "    predicted_stats = teams.loc[(teams['tmID'] == team_id) & (teams['year'] == year - 1)].copy()\n",
    "    predicted_stats['year'] = year\n",
    "    \n",
    "    # Calculate the player stats\n",
    "    predicted_stats['player_average_height'] = team_players_bio['height'].mean()\n",
    "    predicted_stats['player_average_weight'] = team_players_bio['weight'].mean()\n",
    "    predicted_stats['player_total_GP'] = team_players['GP'].sum()\n",
    "    predicted_stats['player_total_GS'] = team_players['GS'].sum()\n",
    "    predicted_stats['player_total_points'] = team_players['points'].sum()\n",
    "    predicted_stats['player_total_oRebounds'] = team_players['oRebounds'].sum()\n",
    "    predicted_stats['player_total_dRebounds'] = team_players['dRebounds'].sum()\n",
    "    predicted_stats['player_total_rebounds'] = team_players['rebounds'].sum()\n",
    "    predicted_stats['player_total_assists'] = team_players['assists'].sum()\n",
    "    predicted_stats['player_total_steals'] = team_players['steals'].sum()\n",
    "    predicted_stats['player_total_blocks'] = team_players['blocks'].sum()\n",
    "    predicted_stats['player_total_turnovers'] = team_players['turnovers'].sum()\n",
    "    predicted_stats['player_total_PF'] = team_players['PF'].sum()\n",
    "    predicted_stats['player_total_fgAttempted'] = team_players['fgAttempted'].sum()\n",
    "    predicted_stats['player_total_fgMade'] = team_players['fgMade'].sum()\n",
    "    predicted_stats['player_total_ftAttempted'] = team_players['ftAttempted'].sum()\n",
    "    predicted_stats['player_total_ftMade'] = team_players['ftMade'].sum()\n",
    "    predicted_stats['player_total_threeAttempted'] = team_players['threeAttempted'].sum()\n",
    "    predicted_stats['player_total_threeMade'] = team_players['threeMade'].sum()\n",
    "    predicted_stats['player_total_dq'] = team_players['dq'].sum()\n",
    "    predicted_stats['player_total_PostGP'] = team_players['PostGP'].sum()\n",
    "    predicted_stats['player_total_PostGS'] = team_players['PostGS'].sum()\n",
    "    predicted_stats['player_total_PostMinutes'] = team_players['PostMinutes'].sum()\n",
    "    predicted_stats['player_total_PostPoints'] = team_players['PostPoints'].sum()\n",
    "    predicted_stats['player_total_PostoRebounds'] = team_players['PostoRebounds'].sum()\n",
    "    predicted_stats['player_total_PostdRebounds'] = team_players['PostdRebounds'].sum()\n",
    "    predicted_stats['player_total_PostRebounds'] = team_players['PostRebounds'].sum()\n",
    "    predicted_stats['player_total_PostAssists'] = team_players['PostAssists'].sum()\n",
    "    predicted_stats['player_total_PostSteals'] = team_players['PostSteals'].sum()\n",
    "    predicted_stats['player_total_PostBlocks'] = team_players['PostBlocks'].sum()\n",
    "    predicted_stats['player_total_PostTurnovers'] = team_players['PostTurnovers'].sum()\n",
    "    predicted_stats['player_total_PostPF'] = team_players['PostPF'].sum()\n",
    "    predicted_stats['player_total_PostfgAttempted'] = team_players['PostfgAttempted'].sum()\n",
    "    predicted_stats['player_total_PostfgMade'] = team_players['PostfgMade'].sum()\n",
    "    predicted_stats['player_total_PostftAttempted'] = team_players['PostftAttempted'].sum()\n",
    "    predicted_stats['player_total_PostftMade'] = team_players['PostftMade'].sum()\n",
    "    predicted_stats['player_total_PostthreeAttempted'] = team_players['PostthreeAttempted'].sum()\n",
    "    predicted_stats['player_total_PostthreeMade'] = team_players['PostthreeMade'].sum()\n",
    "    predicted_stats['player_total_PostDQ'] = team_players['PostDQ'].sum()\n",
    "    predicted_stats['player_total_awards'] = team_players['TotalAwards'].sum()\n",
    "    \n",
    "    coach_experience = calculate_coach_experience_for_team(coaches, team_id, year)\n",
    "    predicted_stats['coach_experience'] = coach_experience\n",
    "\n",
    "    \n",
    "    predicted_stats['playoff'] = \"\"\n",
    "    predicted_stats['firstRound'] = \"\"\n",
    "    predicted_stats['semis'] = \"\"\n",
    "    predicted_stats['finals'] = \"\"\n",
    "    \n",
    "    return predicted_stats\n",
    "\n",
    "\n",
    "# Function that returns a dataframe with all team stats for every year from 1 to year-1 plus the predicted stats for year\n",
    "def get_year_predictions(year):\n",
    "    team_predictions = []  # Use a list to collect rows\n",
    "    for index, row in teams.iterrows():\n",
    "        if row['year'] < year:\n",
    "            team_predictions.append(\n",
    "                teams.loc[(teams['tmID'] == row['tmID']) & (teams['year'] == row['year'])]\n",
    "            )\n",
    "        elif row['year'] == year:\n",
    "            predicted_stats = predict_team_year_stats(row['tmID'], year)\n",
    "            team_predictions.append(predicted_stats)\n",
    "            \n",
    "    return pd.concat(team_predictions, ignore_index=True)\n",
    "\n",
    "\n",
    "# Get the predictions for year 10 and save them to data/clean/year_7_predictions.csv\n",
    "year_10_predictions = get_year_predictions(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data:  (48, 105)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [14, 16]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m real_values \u001b[38;5;241m=\u001b[39m teams[teams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayoff\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Calculate the metrics\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(real_values, predictions, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[0;32m     23\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(real_values, predictions, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:222\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:99\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     73\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:460\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    458\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    463\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [14, 16]"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "print(\"Shape of the data: \", year_10_predictions.shape)\n",
    "train_data = year_10_predictions[year_10_predictions['year'] <= 5].dropna(subset=['playoff'])\n",
    "X = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "y = train_data['playoff'] \n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "year_10_data = year_10_predictions[year_10_predictions['year'] == 4].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "\n",
    "predictions = model.predict(year_10_data)\n",
    "\n",
    "year_10_predictions.loc[year_10_predictions['year'] == 10, 'playoff'] = predictions\n",
    "\n",
    "real_values = teams[teams['year'] == 10]['playoff']\n",
    "\n",
    "# Calculate the metrics\n",
    "accuracy = accuracy_score(real_values, predictions)\n",
    "precision = precision_score(real_values, predictions, pos_label='Y')  \n",
    "recall = recall_score(real_values, predictions, pos_label='Y')\n",
    "f1 = f1_score(real_values, predictions, pos_label='Y')\n",
    "\n",
    "print(\"Model: Random Forest Classifier\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(real_values, predictions, target_names=['N', 'Y']))\n",
    "\n",
    "year_10_predictions.to_csv('data/clean/year_10_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X[trial_features], y)\n\u001b[0;32m     25\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X[trial_features])\n\u001b[1;32m---> 26\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     scores[feature] \u001b[38;5;241m=\u001b[39m score\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Seleciona a melhor feature a ser adicionada\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1279\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1100\u001b[0m     {\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1127\u001b[0m ):\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m \n\u001b[0;32m   1130\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1471\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1292\u001b[0m     {\n\u001b[0;32m   1293\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1320\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1321\u001b[0m ):\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m \n\u001b[0;32m   1324\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;124;03m    0.12...\u001b[39;00m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1471\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1472\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1473\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1477\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1479\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1775\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1612\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[0;32m   1613\u001b[0m \n\u001b[0;32m   1614\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[0;32m   1773\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m _check_zero_division(zero_division)\n\u001b[1;32m-> 1775\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1778\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1564\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1562\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1563\u001b[0m             average_options\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1564\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1565\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but average=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1566\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   1567\u001b[0m         )\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1569\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1570\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) is ignored when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1571\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m). You may use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1574\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1575\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Preparar dados\n",
    "train_data = year_10_predictions[year_10_predictions['year'] <= 9].dropna(subset=['playoff'])\n",
    "X_train = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "y_train = train_data['playoff']\n",
    "\n",
    "# Inicializar o modelo\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Inicializar as listas de features\n",
    "selected_features = []\n",
    "remaining_features = list(X.columns)\n",
    "best_score = 0\n",
    "\n",
    "# Forward Selection\n",
    "for i in range(len(remaining_features)):\n",
    "    scores = {}\n",
    "    for feature in remaining_features:\n",
    "        # Testa a adio da feature\n",
    "        trial_features = selected_features + [feature]\n",
    "        model.fit(X[trial_features], y)\n",
    "        predictions = model.predict(X[trial_features])\n",
    "        score = f1_score(y, predictions, pos_label='Y')\n",
    "        scores[feature] = score\n",
    "\n",
    "    # Seleciona a melhor feature a ser adicionada\n",
    "    best_feature = max(scores, key=scores.get)\n",
    "    if scores[best_feature] > best_score:\n",
    "        best_score = scores[best_feature]\n",
    "        selected_features.append(best_feature)\n",
    "        remaining_features.remove(best_feature)\n",
    "    else:\n",
    "        # Se adicionar uma nova feature no melhorar o desempenho, para\n",
    "        break\n",
    "\n",
    "# Mostrar as features selecionadas\n",
    "print(\"Selected Features:\", selected_features)\n",
    "\n",
    "# Re-treinar o modelo com as features selecionadas\n",
    "model.fit(X[selected_features], y)\n",
    "\n",
    "# Testar o modelo em dados do ano 10\n",
    "year_10_data = teams[teams['year'] == 10].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "predictions = model.predict(year_10_data[selected_features])\n",
    "\n",
    "# Resultados reais\n",
    "real_values = teams[teams['year'] == 10]['playoff']\n",
    "\n",
    "# Avaliar o desempenho\n",
    "accuracy = accuracy_score(real_values, predictions)\n",
    "precision = precision_score(real_values, predictions, pos_label='Y')\n",
    "recall = recall_score(real_values, predictions, pos_label='Y')\n",
    "f1 = f1_score(real_values, predictions, pos_label='Y')\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.5384615384615384\n",
      "Precision: 0.625\n",
      "Recall: 0.625\n",
      "F1 Score: 0.625\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.40      0.40      0.40         5\n",
      "           Y       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.54        13\n",
      "   macro avg       0.51      0.51      0.51        13\n",
      "weighted avg       0.54      0.54      0.54        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "train_data = year_10_predictions[year_10_predictions['year'] <= 9].dropna(subset=['playoff'])\n",
    "X_train = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "y_train = train_data['playoff']\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "X_test = year_10_predictions[year_10_predictions['year'] == 10].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "real_values = teams[teams['year'] == 10]['playoff']\n",
    "\n",
    "X_test = X_test[X_train.columns]  \n",
    "\n",
    "logreg_predictions = logreg_model.predict(X_test)\n",
    "\n",
    "logreg_accuracy = accuracy_score(real_values, logreg_predictions)\n",
    "logreg_precision = precision_score(real_values, logreg_predictions, pos_label='Y')\n",
    "logreg_recall = recall_score(real_values, logreg_predictions, pos_label='Y')\n",
    "logreg_f1 = f1_score(real_values, logreg_predictions, pos_label='Y')\n",
    "\n",
    "print(\"Model: Logistic Regression\")\n",
    "print(f\"Accuracy: {logreg_accuracy}\")\n",
    "print(f\"Precision: {logreg_precision}\")\n",
    "print(f\"Recall: {logreg_recall}\")\n",
    "print(f\"F1 Score: {logreg_f1}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(real_values, logreg_predictions, target_names=['N', 'Y']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Support Vector Machine\n",
      "Accuracy: 0.5384615384615384\n",
      "Precision: 0.625\n",
      "Recall: 0.625\n",
      "F1 Score: 0.625\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.40      0.40      0.40         5\n",
      "           Y       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.54        13\n",
      "   macro avg       0.51      0.51      0.51        13\n",
      "weighted avg       0.54      0.54      0.54        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "train_data = year_10_predictions[year_10_predictions['year'] <= 9].dropna(subset=['playoff'])\n",
    "X_train = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "y_train = train_data['playoff']\n",
    "\n",
    "svm_model = SVC(random_state=42)\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "X_test = year_10_predictions[year_10_predictions['year'] == 10].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "real_values = teams[teams['year'] == 10]['playoff']\n",
    "\n",
    "X_test = X_test[X_train.columns]  \n",
    "\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "svm_accuracy = accuracy_score(real_values, svm_predictions)\n",
    "svm_precision = precision_score(real_values, svm_predictions, pos_label='Y')\n",
    "svm_recall = recall_score(real_values, svm_predictions, pos_label='Y')\n",
    "svm_f1 = f1_score(real_values, svm_predictions, pos_label='Y')\n",
    "\n",
    "print(\"\\nModel: Support Vector Machine\")\n",
    "print(f\"Accuracy: {svm_accuracy}\")\n",
    "print(f\"Precision: {svm_precision}\")\n",
    "print(f\"Recall: {svm_recall}\")\n",
    "print(f\"F1 Score: {svm_f1}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(real_values, svm_predictions, target_names=['N', 'Y']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: K-Nearest Neighbors\n",
      "Accuracy: 0.5384615384615384\n",
      "Precision: 0.625\n",
      "Recall: 0.625\n",
      "F1 Score: 0.625\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.40      0.40      0.40         5\n",
      "           Y       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.54        13\n",
      "   macro avg       0.51      0.51      0.51        13\n",
      "weighted avg       0.54      0.54      0.54        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "train_data = year_10_predictions[year_10_predictions['year'] <= 9].dropna(subset=['playoff'])\n",
    "X_train = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "y_train = train_data['playoff']\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "X_test = year_10_predictions[year_10_predictions['year'] == 10].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "real_values = teams[teams['year'] == 10]['playoff']\n",
    "\n",
    "X_test = X_test[X_train.columns] \n",
    "\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "\n",
    "knn_accuracy = accuracy_score(real_values, knn_predictions)\n",
    "knn_precision = precision_score(real_values, knn_predictions, pos_label='Y')\n",
    "knn_recall = recall_score(real_values, knn_predictions, pos_label='Y')\n",
    "knn_f1 = f1_score(real_values, knn_predictions, pos_label='Y')\n",
    "\n",
    "print(\"\\nModel: K-Nearest Neighbors\")\n",
    "print(f\"Accuracy: {knn_accuracy}\")\n",
    "print(f\"Precision: {knn_precision}\")\n",
    "print(f\"Recall: {knn_recall}\")\n",
    "print(f\"F1 Score: {knn_f1}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(real_values, knn_predictions, target_names=['N', 'Y']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.5384615384615384\n",
      "Precision: 0.625\n",
      "Recall: 0.625\n",
      "F1 Score: 0.625\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.40      0.40      0.40         5\n",
      "           Y       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.54        13\n",
      "   macro avg       0.51      0.51      0.51        13\n",
      "weighted avg       0.54      0.54      0.54        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "train_data = year_10_predictions[year_10_predictions['year'] <= 9].dropna(subset=['playoff'])\n",
    "X_train = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "y_train = train_data['playoff']\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "X_test = year_10_predictions[year_10_predictions['year'] == 10].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "real_values = teams[teams['year'] == 10]['playoff']\n",
    "\n",
    "X_test = X_test[X_train.columns] \n",
    "\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "\n",
    "dt_accuracy = accuracy_score(real_values, dt_predictions)\n",
    "dt_precision = precision_score(real_values, dt_predictions, pos_label='Y')\n",
    "dt_recall = recall_score(real_values, dt_predictions, pos_label='Y')\n",
    "dt_f1 = f1_score(real_values, dt_predictions, pos_label='Y')\n",
    "\n",
    "print(\"\\nModel: Decision Tree\")\n",
    "print(f\"Accuracy: {dt_accuracy}\")\n",
    "print(f\"Precision: {dt_precision}\")\n",
    "print(f\"Recall: {dt_recall}\")\n",
    "print(f\"F1 Score: {dt_f1}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(real_values, dt_predictions, target_names=['N', 'Y']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
