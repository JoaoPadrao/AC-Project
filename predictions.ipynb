{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.read_csv('data/selection/selected_features_teams.csv')\n",
    "players = pd.read_csv('data/clean/cleaned_players.csv')\n",
    "players_teams = pd.read_csv('data/clean/cleaned_players_teams.csv')\n",
    "coaches = pd.read_csv('data/clean/cleaned_coaches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coach_experience_for_team(coaches, team_id, year):\n",
    "    team_coaches = coaches[(coaches['tmID'] == team_id) & (coaches['year'] == year)]\n",
    "    total_games = team_coaches['won'].sum() + team_coaches['lost'].sum()\n",
    "    \n",
    "    total_coach_experience = 0\n",
    "    \n",
    "    for _, coach in team_coaches.iterrows():\n",
    "        coach_history = coaches[(coaches['coachID'] == coach['coachID']) & (coaches['year'] < year)]\n",
    "        coach_history = coach_history.sort_values(by='year', ascending=False).head(year)\n",
    "\n",
    "        weights = list(range(year, 0, -1)) \n",
    "        weighted_winrate = sum(coach_history['winrate'] * weights[:len(coach_history)])\n",
    "        total_awards = coach_history['TotalAwards'].sum()\n",
    "        coach_experience = weighted_winrate + total_awards\n",
    "        \n",
    "        coach_games = coach['won'] + coach['lost']\n",
    "        coach_weight = coach_games / total_games if total_games > 0 else 0\n",
    "        total_coach_experience += coach_experience * coach_weight\n",
    "    \n",
    "    return total_coach_experience\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Team Year Stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year tmID franchID confID  rank playoff firstRound semis finals  won  ...  \\\n",
      "0     7  CHA      CHA     EA   6.0       N        NaN   NaN    NaN  6.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.716346  0.345515    0.341622    0.658378  0.450742  0.713885  0.365782   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.336493    0.663507    -240.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player bondla01w\n",
      "No stats for player currimo01w\n",
      "No stats for player flukety01w\n",
      "No stats for player leuchye01w\n",
      "Team CHI is new in year 7. Using average rookie team stats.\n",
      "     year               tmID             franchID confID  rank playoff  \\\n",
      "147    -1  rookie_team_avg_7  rookie_franch_avg_7      0   0.0       0   \n",
      "\n",
      "    firstRound semis finals    won  ...  o_ft_pct  o_3p_pct  o_oreb_pct  \\\n",
      "147          0     0      0  16.89  ...      0.75      0.34        0.31   \n",
      "\n",
      "     o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  d_oreb_pct  d_dreb_pct  \\\n",
      "147        0.69      0.42      0.75      0.34        0.31        0.69   \n",
      "\n",
      "     pts_diff  \n",
      "147      6.56  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals    won  \\\n",
      "0     7  CHI      CHI      0   0.0       0          0     0      0  16.89   \n",
      "\n",
      "   ...  o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  \\\n",
      "0  ...      0.75      0.34        0.31        0.69      0.42      0.75   \n",
      "\n",
      "   d_3p_pct  d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0      0.34        0.31        0.69      6.56  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player cronika01w\n",
      "No stats for player dupreca01w\n",
      "No stats for player moeggli01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0     7  CON      CON     EA   1.0       Y          W     W      W  26.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.744186  0.348525     0.29009     0.70991  0.397619  0.754591     0.305   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.324675    0.675325     230.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player anderam01w\n",
      "No stats for player mahonme01w\n",
      "No stats for player philler01w\n",
      "No stats for player queenbr01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0     7  DET      DET     EA   4.0       Y          L   NaN    NaN  16.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.657623  0.319328    0.339095    0.660905  0.403085  0.749337  0.337719   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.268173    0.731827     -40.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player osipoir01w\n",
      "No stats for player paliesa01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0     7  HOU      HOU     WE   3.0       Y          W     L    NaN  19.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.763768  0.302439      0.2875      0.7125  0.436214  0.749553  0.349882   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0     0.28512     0.71488      46.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player kostaan01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0     7  IND      IND     EA   2.0       Y          W     L    NaN  21.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.759664  0.320513    0.336957    0.663043  0.431034  0.716511   0.33515   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.281818    0.718182      37.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player atkinla01w\n",
      "No stats for player terryka01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0     7  LAS      LAS     WE   4.0       Y          L   NaN    NaN  17.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0   0.72381  0.320413    0.319721    0.680279  0.418414    0.7433  0.350674   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.318924    0.681076     -19.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player davisbr01w\n",
      "No stats for player ndongem01w\n",
      "No stats for player stansti01w\n",
      "No stats for player vilipda01w\n",
      "No stats for player willili01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0     7  MIN      MIN     WE   6.0       N        NaN   NaN    NaN  14.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.727121  0.349593    0.302439    0.697561  0.426944  0.734797  0.343085   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.326066    0.673934     -77.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player augusse01w\n",
      "No stats for player duffyme01w\n",
      "No stats for player thorbsh01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0     7  NYL      NYL     EA   3.0       Y          L   NaN    NaN  18.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.818841  0.343802     0.24846     0.75154  0.426938  0.726974   0.31407   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.334951    0.665049      31.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player anderam01w\n",
      "No stats for player bakersh01w\n",
      "No stats for player gomisem01w\n",
      "No stats for player ngarsch01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0     7  PHO      PHO     WE   5.0       N        NaN   NaN    NaN  16.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.766234  0.330241    0.322034    0.677966  0.429002  0.726389  0.364458   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.311523    0.688477       7.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player lacyje01w\n",
      "No stats for player pondeca01w\n",
      "No stats for player smithcr01w\n",
      "No stats for player strotan01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0     7  SAC      SAC     WE   1.0       Y          W     W      W  25.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0   0.68516  0.358333    0.353787    0.646213  0.411958  0.732006  0.300532   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.282316    0.717684     236.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player smithki01w\n",
      "No stats for player wilkibr01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals  won  ...  \\\n",
      "0     7  SAS      SAS     WE   7.0       N        NaN   NaN    NaN  7.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.771472  0.324484    0.270613    0.729387  0.436134  0.757774  0.348039   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.332701    0.667299    -260.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player youngso01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0     7  SEA      SEA     WE   2.0       Y          L   NaN    NaN  20.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.790698  0.331002    0.293904    0.706096   0.41239  0.758514  0.317422   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.327451    0.672549      91.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player greenci01w\n",
      "No stats for player turneba01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0     7  WAS      WAS     EA   5.0       N        NaN   NaN    NaN  16.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.710623  0.354902    0.282078    0.717922  0.444979   0.75463   0.34642   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.260742    0.739258     -42.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player blueni01w\n",
      "No stats for player jamesta01w\n",
      "No stats for player teilaza01w\n",
      "Predicted stats for year 7 calculated.\n"
     ]
    }
   ],
   "source": [
    "def predict_team_year_stats(team_id, year): \n",
    "\n",
    "    # Teams stats, considering the most recent year possible and if not available, using the average rookie team stats\n",
    "    team_stats = []\n",
    "\n",
    "    team_previous_stats = teams[(teams['tmID'] == team_id) & (teams['year'] < year)]\n",
    "\n",
    "    if not team_previous_stats.empty:\n",
    "        recent_stats = team_previous_stats.sort_values('year', ascending=False).head(1)\n",
    "        team_stats.append(recent_stats)\n",
    "    else:\n",
    "        print(f\"Team {team_id} is new in year {year}. Using average rookie team stats.\")\n",
    "        rookie_team_stats = teams[teams['tmID'] == f\"rookie_team_avg_{year}\"]\n",
    "        print(rookie_team_stats)\n",
    "        team_stats.append(rookie_team_stats)\n",
    "\n",
    "    predicted_stats = pd.concat(team_stats, ignore_index=True)\n",
    "\n",
    "    predicted_stats['year'] = year\n",
    "    predicted_stats['tmID'] = team_id\n",
    "    predicted_stats['franchID'] = teams[teams['tmID'] == team_id]['franchID'].iloc[0]\n",
    "\n",
    "    print(predicted_stats)\n",
    "   \n",
    "\n",
    "    # Select player ids for the team for that year\n",
    "    players_ids = players_teams[(players_teams['tmID'] == team_id) & (players_teams['year'] == year)]['playerID']\n",
    "    team_players_bio = players[(players['bioID'].isin(players_ids))]\n",
    "    \n",
    "    # Players stats, considering the most recent year possible and if not available, using the average rookie player stats\n",
    "    team_players = []\n",
    "    for player_id in players_ids:\n",
    "        player_stats = players_teams[players_teams['playerID'] == player_id]\n",
    "        if not player_stats.empty:\n",
    "            recent_stats = player_stats[player_stats['year'] < year].sort_values('year', ascending=False).head(1)\n",
    "            if not recent_stats.empty:\n",
    "                team_players.append(recent_stats)\n",
    "            else:\n",
    "                print(f'No stats for player {player_id}')\n",
    "                rookie_player_stats = players_teams[players_teams['playerID'] == f\"average_rookie_{year}\"]  \n",
    "                team_players.append(rookie_player_stats)    \n",
    "\n",
    "\n",
    "    \n",
    "    team_players = pd.concat(team_players, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    # Calculate the player stats\n",
    "    predicted_stats['player_average_height'] = team_players_bio['height'].mean()\n",
    "    predicted_stats['player_average_weight'] = team_players_bio['weight'].mean()\n",
    "    predicted_stats['player_total_GP'] = team_players['GP'].sum()\n",
    "    predicted_stats['player_total_GS'] = team_players['GS'].sum()\n",
    "    predicted_stats['player_total_points'] = team_players['points'].sum()\n",
    "    predicted_stats['player_total_oRebounds'] = team_players['oRebounds'].sum()\n",
    "    predicted_stats['player_total_dRebounds'] = team_players['dRebounds'].sum()\n",
    "    predicted_stats['player_total_rebounds'] = team_players['rebounds'].sum()\n",
    "    predicted_stats['player_total_assists'] = team_players['assists'].sum()\n",
    "    predicted_stats['player_total_steals'] = team_players['steals'].sum()\n",
    "    predicted_stats['player_total_blocks'] = team_players['blocks'].sum()\n",
    "    predicted_stats['player_total_turnovers'] = team_players['turnovers'].sum()\n",
    "    predicted_stats['player_total_PF'] = team_players['PF'].sum()\n",
    "    predicted_stats['player_total_fgAttempted'] = team_players['fgAttempted'].sum()\n",
    "    predicted_stats['player_total_fgMade'] = team_players['fgMade'].sum()\n",
    "    predicted_stats['player_total_ftAttempted'] = team_players['ftAttempted'].sum()\n",
    "    predicted_stats['player_total_ftMade'] = team_players['ftMade'].sum()\n",
    "    predicted_stats['player_total_threeAttempted'] = team_players['threeAttempted'].sum()\n",
    "    predicted_stats['player_total_threeMade'] = team_players['threeMade'].sum()\n",
    "    predicted_stats['player_total_dq'] = team_players['dq'].sum()\n",
    "    predicted_stats['player_total_PostGP'] = team_players['PostGP'].sum()\n",
    "    predicted_stats['player_total_PostGS'] = team_players['PostGS'].sum()\n",
    "    predicted_stats['player_total_PostMinutes'] = team_players['PostMinutes'].sum()\n",
    "    predicted_stats['player_total_PostPoints'] = team_players['PostPoints'].sum()\n",
    "    predicted_stats['player_total_PostoRebounds'] = team_players['PostoRebounds'].sum()\n",
    "    predicted_stats['player_total_PostdRebounds'] = team_players['PostdRebounds'].sum()\n",
    "    predicted_stats['player_total_PostRebounds'] = team_players['PostRebounds'].sum()\n",
    "    predicted_stats['player_total_PostAssists'] = team_players['PostAssists'].sum()\n",
    "    predicted_stats['player_total_PostSteals'] = team_players['PostSteals'].sum()\n",
    "    predicted_stats['player_total_PostBlocks'] = team_players['PostBlocks'].sum()\n",
    "    predicted_stats['player_total_PostTurnovers'] = team_players['PostTurnovers'].sum()\n",
    "    predicted_stats['player_total_PostPF'] = team_players['PostPF'].sum()\n",
    "    predicted_stats['player_total_PostfgAttempted'] = team_players['PostfgAttempted'].sum()\n",
    "    predicted_stats['player_total_PostfgMade'] = team_players['PostfgMade'].sum()\n",
    "    predicted_stats['player_total_PostftAttempted'] = team_players['PostftAttempted'].sum()\n",
    "    predicted_stats['player_total_PostftMade'] = team_players['PostftMade'].sum()\n",
    "    predicted_stats['player_total_PostthreeAttempted'] = team_players['PostthreeAttempted'].sum()\n",
    "    predicted_stats['player_total_PostthreeMade'] = team_players['PostthreeMade'].sum()\n",
    "    predicted_stats['player_total_PostDQ'] = team_players['PostDQ'].sum()\n",
    "    predicted_stats['player_total_awards'] = team_players['TotalAwards'].sum()\n",
    "    \n",
    "    coach_experience = calculate_coach_experience_for_team(coaches, team_id, year)\n",
    "    predicted_stats['coach_experience'] = coach_experience\n",
    "\n",
    "    \n",
    "    predicted_stats['playoff'] = \"\"\n",
    "    predicted_stats['firstRound'] = \"\"\n",
    "    predicted_stats['semis'] = \"\"\n",
    "    predicted_stats['finals'] = \"\"\n",
    "    \n",
    "    return predicted_stats\n",
    "\n",
    "\n",
    "# Function that returns a dataframe with all team stats for every year from 1 to year-1 plus the predicted stats for year\n",
    "def get_year_predictions(year):\n",
    "    team_predictions = []   \n",
    "    for index, row in teams.iterrows():\n",
    "        if row['year'] < year:\n",
    "            team_predictions.append(\n",
    "                teams.loc[(teams['tmID'] == row['tmID']) & (teams['year'] == row['year'])]\n",
    "            )\n",
    "        elif row['year'] == year:\n",
    "            predicted_stats = predict_team_year_stats(row['tmID'], year)\n",
    "            team_predictions.append(predicted_stats)\n",
    "            \n",
    "    print(f\"Predicted stats for year {year} calculated.\")\n",
    "    return pd.concat(team_predictions, ignore_index=True)\n",
    "\n",
    "\n",
    "year_prediction = get_year_predictions(7)\n",
    "\n",
    "year_prediction = year_prediction[~year_prediction['tmID'].str.contains(\"rookie_team_avg\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data before PCA to Year 7:  (88, 75)\n",
      "Shape of the data after PCA to Year 7:  (88, 19)\n",
      "\n",
      "Results for year 7:\n",
      "Model: Random Forest Classifier with PCA (n_components=0.95)\n",
      "Accuracy:  0.9285714285714286\n",
      "Precision:  1.0\n",
      "Recall:  0.875\n",
      "F1 Score:  0.9333333333333333\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.86      1.00      0.92         6\n",
      "           Y       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.93      0.94      0.93        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_RFC_model_with_PCA(year, year_prediction):\n",
    "    \n",
    "    train_data = year_prediction[year_prediction['year'] <= (year-1)].dropna(subset=['playoff'])\n",
    "    print(\"Shape of the data before PCA to Year \" + str(year) + \": \", train_data.shape)\n",
    "    X = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    y = train_data['playoff'] \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # PCA - With n_components=0.95, keep 95% of the variance\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    print(\"Shape of the data after PCA to Year \" + str(year) + \": \", X_pca.shape)\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_pca, y)\n",
    "\n",
    "    year_10_data = year_prediction[year_prediction['year'] == year].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    year_10_data_scaled = scaler.transform(year_10_data)  \n",
    "    year_10_data_pca = pca.transform(year_10_data_scaled)\n",
    "\n",
    "    predictions = model.predict(year_10_data_pca)\n",
    "    year_prediction.loc[year_prediction['year'] == year, 'playoff'] = predictions\n",
    "\n",
    "    real_values = teams[teams['year'] == year]['playoff']\n",
    "\n",
    "    accuracy = accuracy_score(real_values, predictions)\n",
    "    precision = precision_score(real_values, predictions, pos_label='Y')  \n",
    "    recall = recall_score(real_values, predictions, pos_label='Y')\n",
    "    f1 = f1_score(real_values, predictions, pos_label='Y')\n",
    "\n",
    "    print(\"\\nResults for year \" + str(year) + \":\")\n",
    "    print(\"Model: Random Forest Classifier with PCA (n_components=0.95)\")\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(real_values, predictions, target_names=['N', 'Y']))\n",
    "\n",
    "    # Salvar as previsões\n",
    "    year_prediction.to_csv('data/clean/year_prediction_with_pca.csv', index=False)\n",
    "\n",
    "evaluate_RFC_model_with_PCA(7, year_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data:  (102, 75)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 66)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 50\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(classification_report(real_values, predictions, target_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m---> 50\u001b[0m \u001b[43mevaluate_LR_model_with_PCA\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear_prediction\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 21\u001b[0m, in \u001b[0;36mevaluate_LR_model_with_PCA\u001b[1;34m(year, year_prediction)\u001b[0m\n\u001b[0;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_pca, y)\n\u001b[0;32m     20\u001b[0m year_10_data \u001b[38;5;241m=\u001b[39m year_prediction[year_prediction[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m year]\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayoff\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfranchID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirstRound\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msemis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinals\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 21\u001b[0m year_10_data_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear_10_data\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     22\u001b[0m year_10_data_pca \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform(year_10_data_scaled)  \n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Fazer as previsões\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_data.py:1043\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1040\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1042\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1043\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1082\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1080\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m   1081\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m-> 1082\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1085\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m   1086\u001b[0m         )\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1089\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 66)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def evaluate_LR_model_with_PCA(year, year_prediction):\n",
    "    print(\"Shape of the data: \", year_prediction.shape)\n",
    "    \n",
    "    train_data = year_prediction[year_prediction['year'] <= (year-1)].dropna(subset=['playoff'])\n",
    "    X = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    y = train_data['playoff'] \n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "   # PCA - With n_components=0.95, keep 95% of the variance\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    model = LogisticRegression(random_state=42)\n",
    "    model.fit(X_pca, y)\n",
    "\n",
    "    year_10_data = year_prediction[year_prediction['year'] == year].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    year_10_data_scaled = scaler.transform(year_10_data) \n",
    "    year_10_data_pca = pca.transform(year_10_data_scaled)  \n",
    "\n",
    "    # Fazer as previsões\n",
    "    predictions = model.predict(year_10_data_pca)\n",
    "\n",
    "    # Atualizar as previsões no dataframe\n",
    "    year_prediction.loc[year_prediction['year'] == year, 'playoff'] = predictions\n",
    "\n",
    "    # Valores reais para o cálculo das métricas\n",
    "    real_values = teams[teams['year'] == year]['playoff']\n",
    "\n",
    "    # Calcular as métricas\n",
    "    accuracy = accuracy_score(real_values, predictions)\n",
    "    precision = precision_score(real_values, predictions, pos_label='Y')  \n",
    "    recall = recall_score(real_values, predictions, pos_label='Y')\n",
    "    f1 = f1_score(real_values, predictions, pos_label='Y')\n",
    "\n",
    "    print(\"\\nResults for year \" + str(year) + \":\")\n",
    "    print(\"Model: Logistic Regression with PCA and random_state=42\")\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(real_values, predictions, target_names=['N', 'Y']))\n",
    "\n",
    "\n",
    "evaluate_LR_model_with_PCA(10, year_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data:  (142, 75)\n",
      "\n",
      "Results for year 10:\n",
      "Model: Support Vector Machine with PCA and random_state=42\n",
      "Accuracy:  0.6153846153846154\n",
      "Precision:  0.6666666666666666\n",
      "Recall:  0.75\n",
      "F1 Score:  0.7058823529411765\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.50      0.40      0.44         5\n",
      "           Y       0.67      0.75      0.71         8\n",
      "\n",
      "    accuracy                           0.62        13\n",
      "   macro avg       0.58      0.57      0.58        13\n",
      "weighted avg       0.60      0.62      0.61        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def evaluate_SVM_model_with_PCA(year, year_prediction):\n",
    "    print(\"Shape of the data: \", year_prediction.shape)\n",
    "    \n",
    "    train_data = year_prediction[year_prediction['year'] <= (year-1)].dropna(subset=['playoff'])\n",
    "    X = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    y = train_data['playoff'] \n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # PCA - With n_components=0.95, keep 95% of the variance\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    model = SVC(random_state=42)\n",
    "    model.fit(X_pca, y)\n",
    "\n",
    "    year_10_data = year_prediction[year_prediction['year'] == year].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    year_10_data_scaled = scaler.transform(year_10_data)  \n",
    "    year_10_data_pca = pca.transform(year_10_data_scaled) \n",
    "\n",
    "    predictions = model.predict(year_10_data_pca)\n",
    "\n",
    "    year_prediction.loc[year_prediction['year'] == year, 'playoff'] = predictions\n",
    "\n",
    "    real_values = teams[teams['year'] == year]['playoff']\n",
    "\n",
    "    accuracy = accuracy_score(real_values, predictions)\n",
    "    precision = precision_score(real_values, predictions, pos_label='Y')  \n",
    "    recall = recall_score(real_values, predictions, pos_label='Y')\n",
    "    f1 = f1_score(real_values, predictions, pos_label='Y')\n",
    "\n",
    "    print(\"\\nResults for year \" + str(year) + \":\")\n",
    "    print(\"Model: Support Vector Machine with PCA and random_state=42\")\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(real_values, predictions, target_names=['N', 'Y']))\n",
    "\n",
    "\n",
    "evaluate_SVM_model_with_PCA(10, year_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data:  (142, 75)\n",
      "\n",
      "Results for year 10:\n",
      "Model: K-Nearest Neighbors with PCA and n_neighbors=3\n",
      "Accuracy:  0.5384615384615384\n",
      "Precision:  0.625\n",
      "Recall:  0.625\n",
      "F1 Score:  0.625\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.40      0.40      0.40         5\n",
      "           Y       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.54        13\n",
      "   macro avg       0.51      0.51      0.51        13\n",
      "weighted avg       0.54      0.54      0.54        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "def evaluate_KNN_model_with_PCA(year, year_prediction):\n",
    "    print(\"Shape of the data: \", year_prediction.shape)\n",
    "    \n",
    "    train_data = year_prediction[year_prediction['year'] <= (year-1)].dropna(subset=['playoff'])\n",
    "    X = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    y = train_data['playoff'] \n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # PCA - With n_components=0.95, keep 95% of the variance\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=3)\n",
    "    model.fit(X_pca, y)\n",
    "\n",
    "    year_10_data = year_prediction[year_prediction['year'] == year].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    year_10_data_scaled = scaler.transform(year_10_data)  \n",
    "    year_10_data_pca = pca.transform(year_10_data_scaled)  \n",
    "\n",
    "    predictions = model.predict(year_10_data_pca)\n",
    "\n",
    "    year_prediction.loc[year_prediction['year'] == year, 'playoff'] = predictions\n",
    "\n",
    "    real_values = teams[teams['year'] == year]['playoff']\n",
    "\n",
    "    accuracy = accuracy_score(real_values, predictions)\n",
    "    precision = precision_score(real_values, predictions, pos_label='Y')  \n",
    "    recall = recall_score(real_values, predictions, pos_label='Y')\n",
    "    f1 = f1_score(real_values, predictions, pos_label='Y')\n",
    "\n",
    "    print(\"\\nResults for year \" + str(year) + \":\")\n",
    "    print(\"Model: K-Nearest Neighbors with PCA and n_neighbors=3\")\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(real_values, predictions, target_names=['N', 'Y']))\n",
    "\n",
    "evaluate_KNN_model_with_PCA(10, year_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data:  (142, 75)\n",
      "\n",
      "Results for year 10:\n",
      "Model: Decision Tree Classifier with PCA\n",
      "Accuracy:  0.6153846153846154\n",
      "Precision:  0.6666666666666666\n",
      "Recall:  0.75\n",
      "F1 Score:  0.7058823529411765\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.50      0.40      0.44         5\n",
      "           Y       0.67      0.75      0.71         8\n",
      "\n",
      "    accuracy                           0.62        13\n",
      "   macro avg       0.58      0.57      0.58        13\n",
      "weighted avg       0.60      0.62      0.61        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def evaluate_DTC_model_with_PCA(year, year_prediction):\n",
    "    print(\"Shape of the data: \", year_prediction.shape)\n",
    "    \n",
    "    train_data = year_prediction[year_prediction['year'] <= (year-1)].dropna(subset=['playoff'])\n",
    "    X = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    y = train_data['playoff'] \n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # PCA - With n_components=0.95, keep 95% of the variance\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "    model.fit(X_pca, y)\n",
    "\n",
    "    year_10_data = year_prediction[year_prediction['year'] == year].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    year_10_data_scaled = scaler.transform(year_10_data) \n",
    "    year_10_data_pca = pca.transform(year_10_data_scaled)  \n",
    "\n",
    "    predictions = model.predict(year_10_data_pca)\n",
    "\n",
    "    year_prediction.loc[year_prediction['year'] == year, 'playoff'] = predictions\n",
    "\n",
    "    real_values = teams[teams['year'] == year]['playoff']\n",
    "\n",
    "    accuracy = accuracy_score(real_values, predictions)\n",
    "    precision = precision_score(real_values, predictions, pos_label='Y')  \n",
    "    recall = recall_score(real_values, predictions, pos_label='Y')\n",
    "    f1 = f1_score(real_values, predictions, pos_label='Y')\n",
    "\n",
    "    print(\"\\nResults for year \" + str(year) + \":\")\n",
    "    print(\"Model: Decision Tree Classifier with PCA\")\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(real_values, predictions, target_names=['N', 'Y']))\n",
    "\n",
    "evaluate_DTC_model_with_PCA(10, year_prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
