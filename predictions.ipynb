{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.read_csv('data/selection/selected_features_teams.csv')\n",
    "players = pd.read_csv('data/clean/cleaned_players.csv')\n",
    "players_teams = pd.read_csv('data/clean/cleaned_players_teams.csv')\n",
    "coaches = pd.read_csv('data/clean/cleaned_coaches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coach_experience_for_team(coaches, team_id, year):\n",
    "    team_coaches = coaches[(coaches['tmID'] == team_id) & (coaches['year'] == year)]\n",
    "    total_games = team_coaches['won'].sum() + team_coaches['lost'].sum()\n",
    "    \n",
    "    total_coach_experience = 0\n",
    "    \n",
    "    for _, coach in team_coaches.iterrows():\n",
    "        coach_history = coaches[(coaches['coachID'] == coach['coachID']) & (coaches['year'] < year)]\n",
    "        coach_history = coach_history.sort_values(by='year', ascending=False).head(year)\n",
    "\n",
    "        weights = list(range(year, 0, -1)) \n",
    "        weighted_winrate = sum(coach_history['winrate'] * weights[:len(coach_history)])\n",
    "        total_awards = coach_history['TotalAwards'].sum()\n",
    "        coach_experience = weighted_winrate + total_awards\n",
    "        \n",
    "        coach_games = coach['won'] + coach['lost']\n",
    "        coach_weight = coach_games / total_games if total_games > 0 else 0\n",
    "        total_coach_experience += coach_experience * coach_weight\n",
    "    \n",
    "    return total_coach_experience\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Team Year Stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year tmID franchID confID  rank playoff firstRound semis finals  won  ...  \\\n",
      "0    10  ATL      ATL     EA   7.0       N        NaN   NaN    NaN  4.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.747586  0.337793    0.315692    0.684308  0.449867  0.739651  0.342629   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.316996    0.683004    -345.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player lehnish01w\n",
      "No stats for player mccouan01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0    10  CHI      CHI     EA   5.0       N        NaN   NaN    NaN  12.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.694581  0.322581     0.31677     0.68323  0.416251  0.772519  0.334646   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.315517    0.684483     -38.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player nanch01w\n",
      "No stats for player tolivkr01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0    10  CON      CON     EA   2.0       Y          L   NaN    NaN  21.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.745505  0.330344    0.298628    0.701372  0.418126  0.739812  0.320565   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0         0.3         0.7     149.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player blackch01w\n",
      "No stats for player cironkr01w\n",
      "No stats for player ervinla01w\n",
      "No stats for player jekaban01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0    10  DET      DET     EA   1.0       Y          W     W      W  22.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.747312  0.352941    0.324519    0.675481  0.405393  0.760811  0.349026   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.298618    0.701382     150.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player davista02w\n",
      "No stats for player millebr01w\n",
      "No stats for player zellosh01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0    10  IND      IND     EA   4.0       Y          L   NaN    NaN  17.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.754573   0.34139    0.309672    0.690328    0.4189  0.764873  0.325301   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.288642    0.711358      16.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player januabr01w\n",
      "No stats for player wirthch01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0    10  LAS      LAS     WE   3.0       Y          W     L    NaN  20.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.751743   0.31134    0.301092    0.698908  0.384416  0.748336  0.338208   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.318545    0.681455      75.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player wisdoli01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0    10  MIN      MIN     WE   7.0       N        NaN   NaN    NaN  16.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0   0.75463  0.322034    0.308297    0.691703  0.438739  0.756489  0.331276   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.288779    0.711221      46.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player holliqu01w\n",
      "No stats for player mccanra01w\n",
      "No stats for player montaan01w\n",
      "No stats for player montgre01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0    10  NYL      NYL     EA   3.0       Y          W     L    NaN  19.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.750383  0.366856    0.295928    0.704072  0.427184  0.765579  0.358763   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.299574    0.700426      35.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player vaughki01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0    10  PHO      PHO     WE   6.0       N        NaN   NaN    NaN  16.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0   0.83053  0.328103    0.305873    0.694127  0.421138  0.744635   0.34964   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.338983    0.661017       1.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player bonnede01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0    10  SAC      SAC     WE   4.0       Y          L   NaN    NaN  18.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.748775  0.383562    0.349865    0.650135  0.450188  0.754019  0.343173   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.286512    0.713488     -26.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player boddiwh01w\n",
      "No stats for player parisco01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0    10  SAS      SAS     WE   1.0       Y          W     W      L  24.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.808357  0.339518    0.225069    0.774931  0.398063  0.742902  0.287785   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.322554    0.677446     128.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player frazeme01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0    10  SEA      SEA     WE   2.0       Y          L   NaN    NaN  22.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.758242  0.315673    0.292599    0.707401  0.397874  0.752941  0.319109   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.304029    0.695971      87.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player walkeas01w\n",
      "   year tmID franchID confID  rank playoff firstRound semis finals   won  ...  \\\n",
      "0    10  WAS      WAS     EA   6.0       N        NaN   NaN    NaN  10.0  ...   \n",
      "\n",
      "   o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  d_3p_pct  \\\n",
      "0  0.660091  0.354348    0.319788    0.680212  0.443225  0.740789  0.340909   \n",
      "\n",
      "   d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "0    0.279963    0.720037    -233.0  \n",
      "\n",
      "[1 rows x 75 columns]\n",
      "No stats for player colemma01w\n"
     ]
    }
   ],
   "source": [
    "def predict_team_year_stats(team_id, year): \n",
    "\n",
    "    # Teams stats, considering the most recent year possible and if not available, using the average rookie team stats\n",
    "    team_stats = []\n",
    "\n",
    "    team_previous_stats = teams[(teams['tmID'] == team_id) & (teams['year'] < year)]\n",
    "\n",
    "    if not team_previous_stats.empty:\n",
    "        recent_stats = team_previous_stats.sort_values('year', ascending=False).head(1)\n",
    "        team_stats.append(recent_stats)\n",
    "    else:\n",
    "        print(f\"Team {team_id} is new in year {year}. Using average rookie team stats.\")\n",
    "        rookie_team_stats = teams[teams['tmID'] == 'average_rookie_team']\n",
    "        team_stats.append(rookie_team_stats)\n",
    "\n",
    "    predicted_stats = pd.concat(team_stats, ignore_index=True)\n",
    "\n",
    "    predicted_stats['year'] = year\n",
    "    predicted_stats['tmID'] = team_id\n",
    "    predicted_stats['franchID'] = teams[teams['tmID'] == team_id]['franchID'].iloc[0]\n",
    "\n",
    "    print(predicted_stats)\n",
    "   \n",
    "\n",
    "    # Select player ids for the team for that year\n",
    "    players_ids = players_teams[(players_teams['tmID'] == team_id) & (players_teams['year'] == year)]['playerID']\n",
    "    team_players_bio = players[(players['bioID'].isin(players_ids))]\n",
    "    \n",
    "    # Players stats, considering the most recent year possible and if not available, using the average rookie player stats\n",
    "    team_players = []\n",
    "    for player_id in players_ids:\n",
    "        player_stats = players_teams[players_teams['playerID'] == player_id]\n",
    "        if not player_stats.empty:\n",
    "            recent_stats = player_stats[player_stats['year'] < year].sort_values('year', ascending=False).head(1)\n",
    "            if not recent_stats.empty:\n",
    "                team_players.append(recent_stats)\n",
    "            else:\n",
    "                print(f'No stats for player {player_id}')\n",
    "                team_players.append(players_teams[players_teams['playerID'] == 'average_rookie'])         \n",
    "\n",
    "\n",
    "    \n",
    "    team_players = pd.concat(team_players, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    # Calculate the player stats\n",
    "    predicted_stats['player_average_height'] = team_players_bio['height'].mean()\n",
    "    predicted_stats['player_average_weight'] = team_players_bio['weight'].mean()\n",
    "    predicted_stats['player_total_GP'] = team_players['GP'].sum()\n",
    "    predicted_stats['player_total_GS'] = team_players['GS'].sum()\n",
    "    predicted_stats['player_total_points'] = team_players['points'].sum()\n",
    "    predicted_stats['player_total_oRebounds'] = team_players['oRebounds'].sum()\n",
    "    predicted_stats['player_total_dRebounds'] = team_players['dRebounds'].sum()\n",
    "    predicted_stats['player_total_rebounds'] = team_players['rebounds'].sum()\n",
    "    predicted_stats['player_total_assists'] = team_players['assists'].sum()\n",
    "    predicted_stats['player_total_steals'] = team_players['steals'].sum()\n",
    "    predicted_stats['player_total_blocks'] = team_players['blocks'].sum()\n",
    "    predicted_stats['player_total_turnovers'] = team_players['turnovers'].sum()\n",
    "    predicted_stats['player_total_PF'] = team_players['PF'].sum()\n",
    "    predicted_stats['player_total_fgAttempted'] = team_players['fgAttempted'].sum()\n",
    "    predicted_stats['player_total_fgMade'] = team_players['fgMade'].sum()\n",
    "    predicted_stats['player_total_ftAttempted'] = team_players['ftAttempted'].sum()\n",
    "    predicted_stats['player_total_ftMade'] = team_players['ftMade'].sum()\n",
    "    predicted_stats['player_total_threeAttempted'] = team_players['threeAttempted'].sum()\n",
    "    predicted_stats['player_total_threeMade'] = team_players['threeMade'].sum()\n",
    "    predicted_stats['player_total_dq'] = team_players['dq'].sum()\n",
    "    predicted_stats['player_total_PostGP'] = team_players['PostGP'].sum()\n",
    "    predicted_stats['player_total_PostGS'] = team_players['PostGS'].sum()\n",
    "    predicted_stats['player_total_PostMinutes'] = team_players['PostMinutes'].sum()\n",
    "    predicted_stats['player_total_PostPoints'] = team_players['PostPoints'].sum()\n",
    "    predicted_stats['player_total_PostoRebounds'] = team_players['PostoRebounds'].sum()\n",
    "    predicted_stats['player_total_PostdRebounds'] = team_players['PostdRebounds'].sum()\n",
    "    predicted_stats['player_total_PostRebounds'] = team_players['PostRebounds'].sum()\n",
    "    predicted_stats['player_total_PostAssists'] = team_players['PostAssists'].sum()\n",
    "    predicted_stats['player_total_PostSteals'] = team_players['PostSteals'].sum()\n",
    "    predicted_stats['player_total_PostBlocks'] = team_players['PostBlocks'].sum()\n",
    "    predicted_stats['player_total_PostTurnovers'] = team_players['PostTurnovers'].sum()\n",
    "    predicted_stats['player_total_PostPF'] = team_players['PostPF'].sum()\n",
    "    predicted_stats['player_total_PostfgAttempted'] = team_players['PostfgAttempted'].sum()\n",
    "    predicted_stats['player_total_PostfgMade'] = team_players['PostfgMade'].sum()\n",
    "    predicted_stats['player_total_PostftAttempted'] = team_players['PostftAttempted'].sum()\n",
    "    predicted_stats['player_total_PostftMade'] = team_players['PostftMade'].sum()\n",
    "    predicted_stats['player_total_PostthreeAttempted'] = team_players['PostthreeAttempted'].sum()\n",
    "    predicted_stats['player_total_PostthreeMade'] = team_players['PostthreeMade'].sum()\n",
    "    predicted_stats['player_total_PostDQ'] = team_players['PostDQ'].sum()\n",
    "    predicted_stats['player_total_awards'] = team_players['TotalAwards'].sum()\n",
    "    \n",
    "    coach_experience = calculate_coach_experience_for_team(coaches, team_id, year)\n",
    "    predicted_stats['coach_experience'] = coach_experience\n",
    "\n",
    "    \n",
    "    predicted_stats['playoff'] = \"\"\n",
    "    predicted_stats['firstRound'] = \"\"\n",
    "    predicted_stats['semis'] = \"\"\n",
    "    predicted_stats['finals'] = \"\"\n",
    "    \n",
    "    return predicted_stats\n",
    "\n",
    "\n",
    "# Function that returns a dataframe with all team stats for every year from 1 to year-1 plus the predicted stats for year\n",
    "def get_year_predictions(year):\n",
    "    team_predictions = []   \n",
    "    for index, row in teams.iterrows():\n",
    "        if row['year'] < year:\n",
    "            team_predictions.append(\n",
    "                teams.loc[(teams['tmID'] == row['tmID']) & (teams['year'] == row['year'])]\n",
    "            )\n",
    "        elif row['year'] == year:\n",
    "            predicted_stats = predict_team_year_stats(row['tmID'], year)\n",
    "            team_predictions.append(predicted_stats)\n",
    "            \n",
    "    return pd.concat(team_predictions, ignore_index=True)\n",
    "\n",
    "# save 10 year\n",
    "\n",
    "# Get the predictions for year 10 and save them to data/clean/year_7_predictions.csv\n",
    "year_10_predictions = get_year_predictions(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data:  (143, 75)\n",
      "\n",
      "Results for year 10:\n",
      "Model: Random Forest Classifier with n_estimators=100 and random_state=42\n",
      "Accuracy:  0.6153846153846154\n",
      "Precision:  0.6666666666666666\n",
      "Recall:  0.75\n",
      "F1 Score:  0.7058823529411765\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.50      0.40      0.44         5\n",
      "           Y       0.67      0.75      0.71         8\n",
      "\n",
      "    accuracy                           0.62        13\n",
      "   macro avg       0.58      0.57      0.58        13\n",
      "weighted avg       0.60      0.62      0.61        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "def evaluate_RFC_model(year, year_10_predictions):\n",
    "    print(\"Shape of the data: \", year_10_predictions.shape)\n",
    "    train_data = year_10_predictions[year_10_predictions['year'] <= (year-1)].dropna(subset=['playoff'])\n",
    "    X = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    y = train_data['playoff'] \n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    year_10_data = year_10_predictions[year_10_predictions['year'] == year].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    predictions = model.predict(year_10_data)\n",
    "\n",
    "    year_10_predictions.loc[year_10_predictions['year'] == year, 'playoff'] = predictions\n",
    "\n",
    "    real_values = teams[teams['year'] == year]['playoff']\n",
    "\n",
    "    # Calculate the metrics\n",
    "    accuracy = accuracy_score(real_values, predictions)\n",
    "    precision = precision_score(real_values, predictions, pos_label='Y')  \n",
    "    recall = recall_score(real_values, predictions, pos_label='Y')\n",
    "    f1 = f1_score(real_values, predictions, pos_label='Y')\n",
    "\n",
    "    print(\"\\nResults for year \" + str(year) + \":\")\n",
    "    print(\"Model: Random Forest Classifier with n_estimators=100 and random_state=42\")\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(real_values, predictions, target_names=['N', 'Y']))\n",
    "\n",
    "    year_10_predictions.to_csv('data/clean/year_10_predictions1.csv', index=False)\n",
    "\n",
    "evaluate_RFC_model(10, year_10_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data:  (143, 75)\n",
      "\n",
      "Results for year 10:\n",
      "Model: Logistic Regression with random_state=42\n",
      "Accuracy:  0.6153846153846154\n",
      "Precision:  0.6666666666666666\n",
      "Recall:  0.75\n",
      "F1 Score:  0.7058823529411765\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.50      0.40      0.44         5\n",
      "           Y       0.67      0.75      0.71         8\n",
      "\n",
      "    accuracy                           0.62        13\n",
      "   macro avg       0.58      0.57      0.58        13\n",
      "weighted avg       0.60      0.62      0.61        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "def evaluate_LR_model(year, year_10_predictions):\n",
    "    print(\"Shape of the data: \", year_10_predictions.shape)\n",
    "    train_data = year_10_predictions[year_10_predictions['year'] <= (year-1)].dropna(subset=['playoff'])\n",
    "    X = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    y = train_data['playoff'] \n",
    "\n",
    "    model = LogisticRegression(random_state=42)\n",
    "    model.fit(X, y)\n",
    "    year_10_data = year_10_predictions[year_10_predictions['year'] == year].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    predictions = model.predict(year_10_data)\n",
    "\n",
    "    year_10_predictions.loc[year_10_predictions['year'] == year, 'playoff'] = predictions\n",
    "\n",
    "    real_values = teams[teams['year'] == year]['playoff']\n",
    "\n",
    "    # Calculate the metrics\n",
    "    accuracy = accuracy_score(real_values, predictions)\n",
    "    precision = precision_score(real_values, predictions, pos_label='Y')  \n",
    "    recall = recall_score(real_values, predictions, pos_label='Y')\n",
    "    f1 = f1_score(real_values, predictions, pos_label='Y')\n",
    "\n",
    "    print(\"\\nResults for year \" + str(year) + \":\")\n",
    "    print(\"Model: Logistic Regression with random_state=42\")\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(real_values, predictions, target_names=['N', 'Y']))\n",
    "\n",
    "\n",
    "\n",
    "evaluate_LR_model(10, year_10_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data:  (143, 75)\n",
      "\n",
      "Results for year 10:\n",
      "Model: Support Vector Machine with random_state=42\n",
      "Accuracy:  0.6153846153846154\n",
      "Precision:  0.6666666666666666\n",
      "Recall:  0.75\n",
      "F1 Score:  0.7058823529411765\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.50      0.40      0.44         5\n",
      "           Y       0.67      0.75      0.71         8\n",
      "\n",
      "    accuracy                           0.62        13\n",
      "   macro avg       0.58      0.57      0.58        13\n",
      "weighted avg       0.60      0.62      0.61        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "def evaluate_SVM_model(year, year_10_predictions):\n",
    "    print(\"Shape of the data: \", year_10_predictions.shape)\n",
    "    train_data = year_10_predictions[year_10_predictions['year'] <= (year-1)].dropna(subset=['playoff'])\n",
    "    X = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    y = train_data['playoff'] \n",
    "\n",
    "    model = SVC(random_state=42)\n",
    "    model.fit(X, y)\n",
    "    year_10_data = year_10_predictions[year_10_predictions['year'] == year].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    predictions = model.predict(year_10_data)\n",
    "\n",
    "    year_10_predictions.loc[year_10_predictions['year'] == year, 'playoff'] = predictions\n",
    "\n",
    "    real_values = teams[teams['year'] == year]['playoff']\n",
    "\n",
    "    # Calculate the metrics\n",
    "    accuracy = accuracy_score(real_values, predictions)\n",
    "    precision = precision_score(real_values, predictions, pos_label='Y')  \n",
    "    recall = recall_score(real_values, predictions, pos_label='Y')\n",
    "    f1 = f1_score(real_values, predictions, pos_label='Y')\n",
    "\n",
    "    print(\"\\nResults for year \" + str(year) + \":\")\n",
    "    print(\"Model: Support Vector Machine with random_state=42\")\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(real_values, predictions, target_names=['N', 'Y']))\n",
    "\n",
    "evaluate_SVM_model(10, year_10_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data:  (143, 75)\n",
      "\n",
      "Results for year 10:\n",
      "Model: K-Nearest Neighbors with n_neighbors=3\n",
      "Accuracy:  0.5384615384615384\n",
      "Precision:  0.625\n",
      "Recall:  0.625\n",
      "F1 Score:  0.625\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.40      0.40      0.40         5\n",
      "           Y       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.54        13\n",
      "   macro avg       0.51      0.51      0.51        13\n",
      "weighted avg       0.54      0.54      0.54        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "def evaluate_KNN_model(year, year_10_predictions):\n",
    "    print(\"Shape of the data: \", year_10_predictions.shape)\n",
    "    train_data = year_10_predictions[year_10_predictions['year'] <= (year-1)].dropna(subset=['playoff'])\n",
    "    X = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    y = train_data['playoff'] \n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=3)\n",
    "    model.fit(X, y)\n",
    "    year_10_data = year_10_predictions[year_10_predictions['year'] == year].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    predictions = model.predict(year_10_data)\n",
    "\n",
    "    year_10_predictions.loc[year_10_predictions['year'] == year, 'playoff'] = predictions\n",
    "\n",
    "    real_values = teams[teams['year'] == year]['playoff']\n",
    "\n",
    "    # Calculate the metrics\n",
    "    accuracy = accuracy_score(real_values, predictions)\n",
    "    precision = precision_score(real_values, predictions, pos_label='Y')  \n",
    "    recall = recall_score(real_values, predictions, pos_label='Y')\n",
    "    f1 = f1_score(real_values, predictions, pos_label='Y')\n",
    "\n",
    "    print(\"\\nResults for year \" + str(year) + \":\")\n",
    "    print(\"Model: K-Nearest Neighbors with n_neighbors=3\")\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(real_values, predictions, target_names=['N', 'Y']))\n",
    "\n",
    "evaluate_KNN_model(10, year_10_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data:  (143, 75)\n",
      "\n",
      "Results for year 10:\n",
      "Model: Decision Tree Classifier with random_state=42\n",
      "Accuracy:  0.5384615384615384\n",
      "Precision:  0.6\n",
      "Recall:  0.75\n",
      "F1 Score:  0.6666666666666666\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.33      0.20      0.25         5\n",
      "           Y       0.60      0.75      0.67         8\n",
      "\n",
      "    accuracy                           0.54        13\n",
      "   macro avg       0.47      0.47      0.46        13\n",
      "weighted avg       0.50      0.54      0.51        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "def evaluate_DTC_model(year, year_10_predictions):\n",
    "    print(\"Shape of the data: \", year_10_predictions.shape)\n",
    "    train_data = year_10_predictions[year_10_predictions['year'] <= (year-1)].dropna(subset=['playoff'])\n",
    "    X = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    y = train_data['playoff'] \n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "    model.fit(X, y)\n",
    "    year_10_data = year_10_predictions[year_10_predictions['year'] == year].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "    predictions = model.predict(year_10_data)\n",
    "\n",
    "    year_10_predictions.loc[year_10_predictions['year'] == year, 'playoff'] = predictions\n",
    "\n",
    "    real_values = teams[teams['year'] == year]['playoff']\n",
    "\n",
    "    # Calculate the metrics\n",
    "    accuracy = accuracy_score(real_values, predictions)\n",
    "    precision = precision_score(real_values, predictions, pos_label='Y')  \n",
    "    recall = recall_score(real_values, predictions, pos_label='Y')\n",
    "    f1 = f1_score(real_values, predictions, pos_label='Y')\n",
    "\n",
    "    print(\"\\nResults for year \" + str(year) + \":\")\n",
    "    print(\"Model: Decision Tree Classifier with random_state=42\")\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(real_values, predictions, target_names=['N', 'Y']))\n",
    "\n",
    "evaluate_DTC_model(10, year_10_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
