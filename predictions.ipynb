{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.read_csv('data/clean/cleaned_teams.csv')\n",
    "players = pd.read_csv('data/clean/cleaned_players.csv')\n",
    "players_teams = pd.read_csv('data/clean/cleaned_players_teams.csv')\n",
    "coaches = pd.read_csv('data/clean/cleaned_coaches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coach_experience_for_team(coaches, team_id, year):\n",
    "    team_coaches = coaches[(coaches['tmID'] == team_id) & (coaches['year'] == year)]\n",
    "    total_games = team_coaches['won'].sum() + team_coaches['lost'].sum()\n",
    "    \n",
    "    total_coach_experience = 0\n",
    "    \n",
    "    for _, coach in team_coaches.iterrows():\n",
    "        coach_history = coaches[(coaches['coachID'] == coach['coachID']) & (coaches['year'] < year)]\n",
    "        coach_history = coach_history.sort_values(by='year', ascending=False).head(year)\n",
    "\n",
    "        weights = list(range(year, 0, -1)) \n",
    "        weighted_winrate = sum(coach_history['winrate'] * weights[:len(coach_history)])\n",
    "        total_awards = coach_history['TotalAwards'].sum()\n",
    "        coach_experience = weighted_winrate + total_awards\n",
    "        \n",
    "        coach_games = coach['won'] + coach['lost']\n",
    "        coach_weight = coach_games / total_games if total_games > 0 else 0\n",
    "        total_coach_experience += coach_experience * coach_weight\n",
    "    \n",
    "    return total_coach_experience\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Team Year Stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year tmID franchID confID  rank  playoff firstRound semis finals  o_fgm  \\\n",
      "1    10  ATL      ATL     EA     2        1          L   NaN    NaN   1089   \n",
      "\n",
      "   ...  o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  \\\n",
      "1  ...  0.753642  0.304813     0.32089     0.67911  0.421498  0.773234   \n",
      "\n",
      "   d_3p_pct  d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "1  0.341509    0.300681    0.699319        64  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "    year tmID franchID confID  rank  playoff firstRound semis finals  o_fgm  \\\n",
      "12    10  CHI      CHI     EA     5        0        NaN   NaN    NaN    930   \n",
      "\n",
      "    ...  o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  \\\n",
      "12  ...  0.760462  0.394904    0.283472    0.716528  0.442486  0.781403   \n",
      "\n",
      "    d_3p_pct  d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "12  0.347386    0.310554    0.689446      -120  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "    year tmID franchID confID  rank  playoff firstRound semis finals  o_fgm  \\\n",
      "23    10  CON      CON     EA     6        0        NaN   NaN    NaN    966   \n",
      "\n",
      "    ...  o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  \\\n",
      "23  ...   0.74711  0.316119    0.302365    0.697635  0.426208  0.792225   \n",
      "\n",
      "    d_3p_pct  d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "23  0.321721    0.258242    0.741758        -3  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "    year tmID franchID confID  rank  playoff firstRound semis finals  o_fgm  \\\n",
      "33    10  DET      DET     EA     3        1          W     L    NaN    980   \n",
      "\n",
      "    ...  o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  \\\n",
      "33  ...  0.747573  0.350917    0.304241    0.695759  0.409814  0.777368   \n",
      "\n",
      "    d_3p_pct  d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "33  0.340426    0.290645    0.709355         8  \n",
      "\n",
      "[1 rows x 105 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year tmID franchID confID  rank  playoff firstRound semis finals  o_fgm  \\\n",
      "52    10  IND      IND     EA     1        1          W     W      L    890   \n",
      "\n",
      "    ...  o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  \\\n",
      "52  ...  0.821716   0.33438    0.304813    0.695187  0.429178  0.764451   \n",
      "\n",
      "    d_3p_pct  d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "52  0.318841    0.272494    0.727506       105  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "    year tmID franchID confID  rank  playoff firstRound semis finals  o_fgm  \\\n",
      "62    10  LAS      LAS     WE     3        1          W     L    NaN    973   \n",
      "\n",
      "    ...  o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  \\\n",
      "62  ...  0.790909  0.296875    0.292468    0.707532  0.399204   0.76886   \n",
      "\n",
      "    d_3p_pct  d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "62  0.334906    0.304762    0.695238        35  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "    year tmID franchID confID  rank  playoff firstRound semis finals  o_fgm  \\\n",
      "75    10  MIN      MIN     WE     5        0        NaN   NaN    NaN    949   \n",
      "\n",
      "    ...  o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  \\\n",
      "75  ...   0.77154  0.348201    0.298988    0.701012  0.460619  0.773558   \n",
      "\n",
      "    d_3p_pct  d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "75  0.382353    0.272103    0.727897       -96  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "    year tmID franchID confID  rank  playoff firstRound semis finals  o_fgm  \\\n",
      "85    10  NYL      NYL     EA     7        0        NaN   NaN    NaN    900   \n",
      "\n",
      "    ...  o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  \\\n",
      "85  ...  0.786942  0.357746     0.25878     0.74122  0.420028  0.789004   \n",
      "\n",
      "    d_3p_pct  d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "85   0.34657    0.277038    0.722962       -23  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "    year tmID franchID confID  rank  playoff firstRound semis finals  o_fgm  \\\n",
      "98    10  PHO      PHO     WE     1        1          W     W      W   1128   \n",
      "\n",
      "    ...  o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  \\\n",
      "98  ...  0.855053  0.386466    0.238655    0.761345  0.423703  0.749706   \n",
      "\n",
      "    d_3p_pct  d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "98  0.337171    0.327626    0.672374       125  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "     year tmID franchID confID  rank  playoff firstRound semis finals  o_fgm  \\\n",
      "111    10  SAC      SAC     WE     6        0        NaN   NaN    NaN    946   \n",
      "\n",
      "     ...  o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  \\\n",
      "111  ...  0.787634  0.339332    0.338821    0.661179  0.447546  0.817406   \n",
      "\n",
      "     d_3p_pct  d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "111  0.369205    0.317121    0.682879       -80  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "     year tmID franchID confID  rank  playoff firstRound semis finals  o_fgm  \\\n",
      "118    10  SAS      SAS     WE     4        1          L   NaN    NaN    936   \n",
      "\n",
      "     ...  o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  \\\n",
      "118  ...  0.777955  0.346414    0.267874    0.732126  0.438789  0.787097   \n",
      "\n",
      "     d_3p_pct  d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "118  0.346693    0.306397    0.693603       -46  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "     year tmID franchID confID  rank  playoff firstRound semis finals  o_fgm  \\\n",
      "128    10  SEA      SEA     WE     2        1          L   NaN    NaN    909   \n",
      "\n",
      "     ...  o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  \\\n",
      "128  ...  0.785007  0.351852    0.286232    0.713768  0.410233   0.76006   \n",
      "\n",
      "     d_3p_pct  d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "128  0.345299    0.307978    0.692022        68  \n",
      "\n",
      "[1 rows x 105 columns]\n",
      "     year tmID franchID confID  rank  playoff firstRound semis finals  o_fgm  \\\n",
      "141    10  WAS      WAS     EA     4        1          L   NaN    NaN    933   \n",
      "\n",
      "     ...  o_ft_pct  o_3p_pct  o_oreb_pct  o_dreb_pct  d_fg_pct  d_ft_pct  \\\n",
      "141  ...   0.70133  0.326291    0.325777    0.674223  0.432692  0.754967   \n",
      "\n",
      "     d_3p_pct  d_oreb_pct  d_dreb_pct  pts_diff  \n",
      "141  0.338912    0.289829    0.710171       -37  \n",
      "\n",
      "[1 rows x 105 columns]\n"
     ]
    }
   ],
   "source": [
    "def predict_team_year_stats(team_id, year): \n",
    "    # Select player ids for the team for that year\n",
    "    players_ids = players_teams[(players_teams['tmID'] == team_id) & (players_teams['year'] == year)]['playerID']\n",
    "    \n",
    "    # Select player stats for last year\n",
    "    team_players = players_teams[(players_teams['playerID'].isin(players_ids)) & (players_teams['year'] == year - 1)]\n",
    "    team_players_bio = players[(players['bioID'].isin(players_ids))]\n",
    "\n",
    "    print(teams.loc[(teams['tmID'] == team_id) & (teams['year'] == year)])\n",
    "    \n",
    "    # Copy the stats from the previous year into the new year    \n",
    "    predicted_stats = teams.loc[(teams['tmID'] == team_id) & (teams['year'] == year - 1)].copy()\n",
    "    predicted_stats['year'] = year\n",
    "    \n",
    "    # Calculate the player stats\n",
    "    predicted_stats['player_average_height'] = team_players_bio['height'].mean()\n",
    "    predicted_stats['player_average_weight'] = team_players_bio['weight'].mean()\n",
    "    predicted_stats['player_total_GP'] = team_players['GP'].sum()\n",
    "    predicted_stats['player_total_GS'] = team_players['GS'].sum()\n",
    "    predicted_stats['player_total_points'] = team_players['points'].sum()\n",
    "    predicted_stats['player_total_oRebounds'] = team_players['oRebounds'].sum()\n",
    "    predicted_stats['player_total_dRebounds'] = team_players['dRebounds'].sum()\n",
    "    predicted_stats['player_total_rebounds'] = team_players['rebounds'].sum()\n",
    "    predicted_stats['player_total_assists'] = team_players['assists'].sum()\n",
    "    predicted_stats['player_total_steals'] = team_players['steals'].sum()\n",
    "    predicted_stats['player_total_blocks'] = team_players['blocks'].sum()\n",
    "    predicted_stats['player_total_turnovers'] = team_players['turnovers'].sum()\n",
    "    predicted_stats['player_total_PF'] = team_players['PF'].sum()\n",
    "    predicted_stats['player_total_fgAttempted'] = team_players['fgAttempted'].sum()\n",
    "    predicted_stats['player_total_fgMade'] = team_players['fgMade'].sum()\n",
    "    predicted_stats['player_total_ftAttempted'] = team_players['ftAttempted'].sum()\n",
    "    predicted_stats['player_total_ftMade'] = team_players['ftMade'].sum()\n",
    "    predicted_stats['player_total_threeAttempted'] = team_players['threeAttempted'].sum()\n",
    "    predicted_stats['player_total_threeMade'] = team_players['threeMade'].sum()\n",
    "    predicted_stats['player_total_dq'] = team_players['dq'].sum()\n",
    "    predicted_stats['player_total_PostGP'] = team_players['PostGP'].sum()\n",
    "    predicted_stats['player_total_PostGS'] = team_players['PostGS'].sum()\n",
    "    predicted_stats['player_total_PostMinutes'] = team_players['PostMinutes'].sum()\n",
    "    predicted_stats['player_total_PostPoints'] = team_players['PostPoints'].sum()\n",
    "    predicted_stats['player_total_PostoRebounds'] = team_players['PostoRebounds'].sum()\n",
    "    predicted_stats['player_total_PostdRebounds'] = team_players['PostdRebounds'].sum()\n",
    "    predicted_stats['player_total_PostRebounds'] = team_players['PostRebounds'].sum()\n",
    "    predicted_stats['player_total_PostAssists'] = team_players['PostAssists'].sum()\n",
    "    predicted_stats['player_total_PostSteals'] = team_players['PostSteals'].sum()\n",
    "    predicted_stats['player_total_PostBlocks'] = team_players['PostBlocks'].sum()\n",
    "    predicted_stats['player_total_PostTurnovers'] = team_players['PostTurnovers'].sum()\n",
    "    predicted_stats['player_total_PostPF'] = team_players['PostPF'].sum()\n",
    "    predicted_stats['player_total_PostfgAttempted'] = team_players['PostfgAttempted'].sum()\n",
    "    predicted_stats['player_total_PostfgMade'] = team_players['PostfgMade'].sum()\n",
    "    predicted_stats['player_total_PostftAttempted'] = team_players['PostftAttempted'].sum()\n",
    "    predicted_stats['player_total_PostftMade'] = team_players['PostftMade'].sum()\n",
    "    predicted_stats['player_total_PostthreeAttempted'] = team_players['PostthreeAttempted'].sum()\n",
    "    predicted_stats['player_total_PostthreeMade'] = team_players['PostthreeMade'].sum()\n",
    "    predicted_stats['player_total_PostDQ'] = team_players['PostDQ'].sum()\n",
    "    predicted_stats['player_total_awards'] = team_players['TotalAwards'].sum()\n",
    "    \n",
    "    coach_experience = calculate_coach_experience_for_team(coaches, team_id, year)\n",
    "    predicted_stats['coach_experience'] = coach_experience\n",
    "\n",
    "    \n",
    "    predicted_stats['playoff'] = \"\"\n",
    "    predicted_stats['firstRound'] = \"\"\n",
    "    predicted_stats['semis'] = \"\"\n",
    "    predicted_stats['finals'] = \"\"\n",
    "    \n",
    "    return predicted_stats\n",
    "\n",
    "\n",
    "# Function that returns a dataframe with all team stats for every year from 1 to year-1 plus the predicted stats for year\n",
    "def get_year_predictions(year):\n",
    "    team_predictions = []  # Use a list to collect rows\n",
    "    for index, row in teams.iterrows():\n",
    "        if row['year'] < year:\n",
    "            team_predictions.append(\n",
    "                teams.loc[(teams['tmID'] == row['tmID']) & (teams['year'] == row['year'])]\n",
    "            )\n",
    "        elif row['year'] == year:\n",
    "            predicted_stats = predict_team_year_stats(row['tmID'], year)\n",
    "            team_predictions.append(predicted_stats)\n",
    "            \n",
    "    return pd.concat(team_predictions, ignore_index=True)\n",
    "\n",
    "\n",
    "# Get the predictions for year 10 and save them to data/clean/year_7_predictions.csv\n",
    "year_10_predictions = get_year_predictions(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data:  (142, 105)\n",
      "Unique values in target (y): [0 1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/daniel/Documents/uni/ac/AC-Project/predictions.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/daniel/Documents/uni/ac/AC-Project/predictions.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mUnique values in target (y):\u001b[39m\u001b[39m\"\u001b[39m, y\u001b[39m.\u001b[39munique())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/daniel/Documents/uni/ac/AC-Project/predictions.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m model \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/daniel/Documents/uni/ac/AC-Project/predictions.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/daniel/Documents/uni/ac/AC-Project/predictions.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m year_10_data \u001b[39m=\u001b[39m year_10_predictions[year_10_predictions[\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m10\u001b[39m]\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mplayoff\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtmID\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfranchID\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mconfID\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfirstRound\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msemis\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfinals\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrank\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/daniel/Documents/uni/ac/AC-Project/predictions.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m year_10_data[\u001b[39m'\u001b[39m\u001b[39mplayoff_prob\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_proba(year_10_data)[:, \u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/ensemble/_forest.py:421\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    415\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSum of y is not strictly positive which \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis necessary for Poisson regression.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m         )\n\u001b[1;32m    419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_samples, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape\n\u001b[0;32m--> 421\u001b[0m y, expanded_class_weight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_y_class_weight(y)\n\u001b[1;32m    423\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(y, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m!=\u001b[39m DOUBLE \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m y\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mcontiguous:\n\u001b[1;32m    424\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mascontiguousarray(y, dtype\u001b[39m=\u001b[39mDOUBLE)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/ensemble/_forest.py:831\u001b[0m, in \u001b[0;36mForestClassifier._validate_y_class_weight\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_y_class_weight\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[0;32m--> 831\u001b[0m     check_classification_targets(y)\n\u001b[1;32m    833\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(y)\n\u001b[1;32m    834\u001b[0m     expanded_class_weight \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/utils/multiclass.py:221\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    213\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    214\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[1;32m    215\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    216\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m ]:\n\u001b[0;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m{\u001b[39;00my_type\u001b[39m}\u001b[39;00m\u001b[39m. Maybe you are trying to fit a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mclassifier, which expects discrete classes on a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mregression target with continuous values.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "print(\"Shape of the data: \", year_10_predictions.shape)\n",
    "train_data = year_10_predictions[year_10_predictions['year'] <= 9].dropna(subset=['playoff'])\n",
    "X = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "y = train_data['playoff'] \n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "year_10_data = year_10_predictions[year_10_predictions['year'] == 10].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "\n",
    "year_10_data['playoff_prob'] = model.predict_proba(year_10_data)[:, 1]\n",
    "year_10_data['confID'] = year_10_predictions.loc[year_10_predictions['year'] == 10, 'confID']\n",
    "\n",
    "year_10_predictions['playoff'] = 0 \n",
    "for conf in year_10_data['confID'].unique():\n",
    "    conf_teams = year_10_data[year_10_data['confID'] == conf]\n",
    "    top_teams = conf_teams.nlargest(4, 'playoff_prob')\n",
    "    year_10_predictions.loc[top_teams.index, 'playoff'] = 1\n",
    "\n",
    "adj_probs = year_10_predictions.loc[year_10_predictions['year'] == 10, 'playoff']\n",
    "\n",
    "actual_labels = year_10_predictions.loc[teams['year'] == 10, 'playoff'] \n",
    "\n",
    "error = sum(abs(adj_probs - actual_labels))\n",
    "theoretical_max_error = len(actual_labels)  \n",
    "theoretical_best_error = 0  \n",
    "\n",
    "print(f\"Error: {error}\")\n",
    "print(f\"Theoretical Max Error: {theoretical_max_error}\")\n",
    "print(f\"Theoretical Best Error: {theoretical_best_error}\")\n",
    "\n",
    "\n",
    "year_10_predictions.to_csv('data/clean/year_10_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/daniel/Documents/uni/ac/AC-Project/predictions.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/daniel/Documents/uni/ac/AC-Project/predictions.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m y_train \u001b[39m=\u001b[39m train_data[\u001b[39m'\u001b[39m\u001b[39mplayoff\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/daniel/Documents/uni/ac/AC-Project/predictions.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m logreg_model \u001b[39m=\u001b[39m LogisticRegression(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/daniel/Documents/uni/ac/AC-Project/predictions.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m logreg_model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/daniel/Documents/uni/ac/AC-Project/predictions.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m X_test \u001b[39m=\u001b[39m year_10_predictions[year_10_predictions[\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m10\u001b[39m]\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mplayoff\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtmID\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfranchID\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mconfID\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfirstRound\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msemis\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfinals\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrank\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/daniel/Documents/uni/ac/AC-Project/predictions.ipynb#X22sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m real_values \u001b[39m=\u001b[39m teams[teams[\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m10\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mplayoff\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/linear_model/_logistic.py:1246\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1244\u001b[0m classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\n\u001b[1;32m   1245\u001b[0m \u001b[39mif\u001b[39;00m n_classes \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> 1246\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1247\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis solver needs samples of at least 2 classes\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1248\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m in the data, but the data contains only one\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1249\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m class: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1250\u001b[0m         \u001b[39m%\u001b[39m classes_[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1251\u001b[0m     )\n\u001b[1;32m   1253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   1254\u001b[0m     n_classes \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "train_data = year_10_predictions[year_10_predictions['year'] <= 9].dropna(subset=['playoff'])\n",
    "X_train = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "y_train = train_data['playoff']\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "X_test = year_10_predictions[year_10_predictions['year'] == 10].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "real_values = teams[teams['year'] == 10]['playoff']\n",
    "\n",
    "X_test = X_test[X_train.columns]  \n",
    "\n",
    "logreg_predictions = logreg_model.predict(X_test)\n",
    "\n",
    "logreg_accuracy = accuracy_score(real_values, logreg_predictions)\n",
    "logreg_precision = precision_score(real_values, logreg_predictions, pos_label='Y')\n",
    "logreg_recall = recall_score(real_values, logreg_predictions, pos_label='Y')\n",
    "logreg_f1 = f1_score(real_values, logreg_predictions, pos_label='Y')\n",
    "\n",
    "print(\"Model: Logistic Regression\")\n",
    "print(f\"Accuracy: {logreg_accuracy}\")\n",
    "print(f\"Precision: {logreg_precision}\")\n",
    "print(f\"Recall: {logreg_recall}\")\n",
    "print(f\"F1 Score: {logreg_f1}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(real_values, logreg_predictions, target_names=['N', 'Y']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Support Vector Machine\n",
      "Accuracy: 0.5384615384615384\n",
      "Precision: 0.625\n",
      "Recall: 0.625\n",
      "F1 Score: 0.625\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.40      0.40      0.40         5\n",
      "           Y       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.54        13\n",
      "   macro avg       0.51      0.51      0.51        13\n",
      "weighted avg       0.54      0.54      0.54        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "train_data = year_10_predictions[year_10_predictions['year'] <= 9].dropna(subset=['playoff'])\n",
    "X_train = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "y_train = train_data['playoff']\n",
    "\n",
    "svm_model = SVC(random_state=42)\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "X_test = year_10_predictions[year_10_predictions['year'] == 10].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "real_values = teams[teams['year'] == 10]['playoff']\n",
    "\n",
    "X_test = X_test[X_train.columns]  \n",
    "\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "svm_accuracy = accuracy_score(real_values, svm_predictions)\n",
    "svm_precision = precision_score(real_values, svm_predictions, pos_label='Y')\n",
    "svm_recall = recall_score(real_values, svm_predictions, pos_label='Y')\n",
    "svm_f1 = f1_score(real_values, svm_predictions, pos_label='Y')\n",
    "\n",
    "print(\"\\nModel: Support Vector Machine\")\n",
    "print(f\"Accuracy: {svm_accuracy}\")\n",
    "print(f\"Precision: {svm_precision}\")\n",
    "print(f\"Recall: {svm_recall}\")\n",
    "print(f\"F1 Score: {svm_f1}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(real_values, svm_predictions, target_names=['N', 'Y']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: K-Nearest Neighbors\n",
      "Accuracy: 0.5384615384615384\n",
      "Precision: 0.625\n",
      "Recall: 0.625\n",
      "F1 Score: 0.625\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.40      0.40      0.40         5\n",
      "           Y       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.54        13\n",
      "   macro avg       0.51      0.51      0.51        13\n",
      "weighted avg       0.54      0.54      0.54        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "train_data = year_10_predictions[year_10_predictions['year'] <= 9].dropna(subset=['playoff'])\n",
    "X_train = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "y_train = train_data['playoff']\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "X_test = year_10_predictions[year_10_predictions['year'] == 10].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "real_values = teams[teams['year'] == 10]['playoff']\n",
    "\n",
    "X_test = X_test[X_train.columns] \n",
    "\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "\n",
    "knn_accuracy = accuracy_score(real_values, knn_predictions)\n",
    "knn_precision = precision_score(real_values, knn_predictions, pos_label='Y')\n",
    "knn_recall = recall_score(real_values, knn_predictions, pos_label='Y')\n",
    "knn_f1 = f1_score(real_values, knn_predictions, pos_label='Y')\n",
    "\n",
    "print(\"\\nModel: K-Nearest Neighbors\")\n",
    "print(f\"Accuracy: {knn_accuracy}\")\n",
    "print(f\"Precision: {knn_precision}\")\n",
    "print(f\"Recall: {knn_recall}\")\n",
    "print(f\"F1 Score: {knn_f1}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(real_values, knn_predictions, target_names=['N', 'Y']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.6153846153846154\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.75\n",
      "F1 Score: 0.7058823529411765\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.50      0.40      0.44         5\n",
      "           Y       0.67      0.75      0.71         8\n",
      "\n",
      "    accuracy                           0.62        13\n",
      "   macro avg       0.58      0.57      0.58        13\n",
      "weighted avg       0.60      0.62      0.61        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "train_data = year_10_predictions[year_10_predictions['year'] <= 9].dropna(subset=['playoff'])\n",
    "X_train = train_data.drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "y_train = train_data['playoff']\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "X_test = year_10_predictions[year_10_predictions['year'] == 10].drop(columns=['playoff', 'year', 'tmID', 'franchID', 'confID', 'firstRound', 'semis', 'finals', 'rank'])\n",
    "real_values = teams[teams['year'] == 10]['playoff']\n",
    "\n",
    "X_test = X_test[X_train.columns] \n",
    "\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "\n",
    "dt_accuracy = accuracy_score(real_values, dt_predictions)\n",
    "dt_precision = precision_score(real_values, dt_predictions, pos_label='Y')\n",
    "dt_recall = recall_score(real_values, dt_predictions, pos_label='Y')\n",
    "dt_f1 = f1_score(real_values, dt_predictions, pos_label='Y')\n",
    "\n",
    "print(\"\\nModel: Decision Tree\")\n",
    "print(f\"Accuracy: {dt_accuracy}\")\n",
    "print(f\"Precision: {dt_precision}\")\n",
    "print(f\"Recall: {dt_recall}\")\n",
    "print(f\"F1 Score: {dt_f1}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(real_values, dt_predictions, target_names=['N', 'Y']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
